{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df7bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fetch URL https://pypi.org/simple/sb3-contrib/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/sb3-contrib/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))) - skipping\n",
      "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))) - skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "ERROR: Could not find a version that satisfies the requirement sb3-contrib\n",
      "ERROR: No matching distribution found for sb3-contrib\n"
     ]
    }
   ],
   "source": [
    "pip install sb3-contrib\n",
    "# 注意：如果安装失败，尝试关闭vpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccedee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import MaskablePPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1471504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415bd733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec59c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:38: UserWarning: It seems that your observation space  is an image but the upper and lower bounds are not in [0, 255]. Because the CNN policy normalize automatically the observation you may encounter issue if the values are not in that range.\n",
      "  warnings.warn(\n",
      "D:\\apps\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:51: UserWarning: The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom features extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "from gym_reversi import ReversiEnv\n",
    "\n",
    "env = ReversiEnv(player_color='black', opponent = \"random\", board_size=8)\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "check_env(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e86e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "??make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7754847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "??ActionMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b252c64",
   "metadata": {},
   "source": [
    "### Maskable PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05f812e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inplanes:4\n",
      "planes:64\n",
      "inplanes:64\n",
      "planes:64\n",
      "inplanes:64\n",
      "planes:128\n",
      "Logging to models/ppo_8x8_resnet_debug/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.5      |\n",
      "| time/              |          |\n",
      "|    fps             | 206      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 256      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.375       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 512         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062315006 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0371     |\n",
      "|    n_updates            | 1568        |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 0.0327      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.2       |\n",
      "|    ep_rew_mean          | 0.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 768        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05087828 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.64      |\n",
      "|    explained_variance   | -0.158     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0456    |\n",
      "|    n_updates            | 1572       |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 0.0669     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.438       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039254464 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0835     |\n",
      "|    n_updates            | 1576        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 0.0507      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 1280        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.085992575 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 0.052       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047597714 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.413      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0572     |\n",
      "|    n_updates            | 1584        |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 0.0717      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.2      |\n",
      "|    ep_rew_mean          | 0.321     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 113       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 1792      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0605711 |\n",
      "|    clip_fraction        | 0.369     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.58     |\n",
      "|    explained_variance   | -0.279    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0476   |\n",
      "|    n_updates            | 1588      |\n",
      "|    policy_gradient_loss | -0.041    |\n",
      "|    value_loss           | 0.0564    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.2       |\n",
      "|    ep_rew_mean          | 0.354      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06497264 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0832    |\n",
      "|    n_updates            | 1592       |\n",
      "|    policy_gradient_loss | -0.0382    |\n",
      "|    value_loss           | 0.0471     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.355       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 2304        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058455497 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0535     |\n",
      "|    n_updates            | 1596        |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 0.0343      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063562684 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0921     |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 0.0279      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-08982d8f4cb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;31m# model.learn(int(2e4))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"train time: {time.time()-t0}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\sb3_contrib\\ppo_mask\\ppo_mask.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, use_masking, progress_bar)\u001b[0m\n\u001b[0;32m    545\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\sb3_contrib\\ppo_mask\\ppo_mask.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m                 \u001b[1;31m# Value loss using the TD(gae_lambda) target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mvalue_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m                 \u001b[0mvalue_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;31m# Entropy loss favor exploration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "import os\n",
    "# current_path = os.getcwd()\n",
    "# sys.path.append(current_path)\n",
    "import os\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "# from stable_baselines3 import DQN, DDPG, A2C, PPO,SAC,TD3\n",
    "from stable_baselines3 import PPO\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "import time\n",
    "from gym_reversi import ReversiEnv\n",
    "from custom_feature_extractor import CustomCNN\n",
    "\n",
    "t0=time.time()\n",
    "\n",
    "# There already exists an environment generator\n",
    "# that will make and wrap atari environments correctly.\n",
    "# Here we are also multi-worker training (n_envs=4 => 4 environments)\n",
    "# vec_env = make_atari_env(\"PongNoFrameskip-v4\", n_envs=4, seed=0)\n",
    "# env = make_atari_env(\"BreakoutNoFrameskip-v4\", seed=0)\n",
    "# vec_env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=4, \n",
    "# #                          seed=0\n",
    "#                         )\n",
    "# # Frame-stacking with 4 frames\n",
    "# vec_env = VecFrameStack(vec_env, n_stack=4)\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    # Do whatever you'd like in this function to return the action mask\n",
    "    # for the current env. In this example, we assume the env has a\n",
    "    # helpful method we can rely on.\n",
    "    return env.valid_action_mask()\n",
    "\n",
    "# backbone= 'resnet'\n",
    "backbone= 'cnn'\n",
    "n_channels = 3\n",
    "\n",
    "\n",
    "board_size=8\n",
    "total_timesteps=10_0000\n",
    "# PolicyModel = PPO\n",
    "PolicyModel = MaskablePPO\n",
    "# PolicyModel = TD3\n",
    "n_envs = 4\n",
    "\n",
    "greedy_rate=0\n",
    "verbose = 0\n",
    "\n",
    "tensorboard_log = f\"models/ppo_{board_size}x{board_size}_{backbone}_debug/\"\n",
    "if not os.path.isdir(tensorboard_log):\n",
    "    os.makedirs(tensorboard_log)\n",
    "model_path = os.path.join(tensorboard_log, \"model\")\n",
    "opponent_model_path=\"random\"\n",
    "# opponent_model_path=os.path.join(tensorboard_log, \"opponent_model\")\n",
    "\n",
    "\n",
    "if opponent_model_path != \"random\":\n",
    "    opponent_model = PolicyModel.load(opponent_model_path)\n",
    "else:\n",
    "    opponent_model = \"random\"\n",
    "\n",
    "env = ReversiEnv(opponent=opponent_model, is_train=True, board_size=board_size, n_channels=4,\n",
    "                 greedy_rate=greedy_rate, verbose=verbose)\n",
    "\n",
    "# env = ActionMasker(env, mask_fn)  # Wrap to enable masking\n",
    "\n",
    "vec_env = env\n",
    "if n_envs > 1:\n",
    "    # multi-worker training (n_envs=4 => 4 environments)\n",
    "    vec_env = make_vec_env(ReversiEnv, n_envs=n_envs, seed=None,\n",
    "                           env_kwargs={\n",
    "                               \"opponent\": opponent_model,\n",
    "                               \"is_train\": True,\n",
    "                               \"board_size\": board_size,\n",
    "                               \"greedy_rate\": greedy_rate,\n",
    "                               \"verbose\": verbose},\n",
    "                        )\n",
    "\n",
    "    \n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=256,\n",
    "                                   backbone=backbone,\n",
    "                                   net_arch=[64, 64, 128],\n",
    "#                                    net_arch=[32, 64, 64],\n",
    "                                   kernel_size=3, \n",
    "                                   stride=1, \n",
    "                                   padding='same', \n",
    "                                   is_batch_norm=False),\n",
    "    net_arch=[256, 256], \n",
    "    normalize_images=False\n",
    ")\n",
    "    \n",
    "try:\n",
    "    model = PolicyModel.load(model_path, env=vec_env)\n",
    "except Exception:\n",
    "    print(f\"load model from self.model_path: {model_path} error\")\n",
    "    model = PolicyModel(MaskableActorCriticPolicy, vec_env,\n",
    "                  policy_kwargs=policy_kwargs,\n",
    "                  learning_rate=2.5e-4,  # learning_rate=2.5e-4,\n",
    "                  ent_coef=0.01,\n",
    "                  n_steps=64, # n_steps=128,\n",
    "                  n_epochs=4,\n",
    "                  batch_size=32, # batch_size=256,\n",
    "                  gamma=0.9,\n",
    "                  gae_lambda=0.9,\n",
    "                  clip_range=0.2,\n",
    "                  vf_coef=0.5,\n",
    "                  verbose=1,\n",
    "                  tensorboard_log=tensorboard_log)\n",
    "\n",
    "t0 = time.time()\n",
    "# model.learn(int(2e4))\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "model.save(model_path)\n",
    "print(f\"train time: {time.time()-t0}\")\n",
    "\n",
    "# vec_env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=1)\n",
    "# vec_env = VecFrameStack(vec_env, n_stack=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0cda6dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00029576466371269896"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.85**50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e254047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard --logdir ./reversi/models/Reversi_ppo/PPO_7/ --port=6016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e676a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from stable_baselines3 import PPO\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "PolicyModel = MaskablePPO\n",
    "\n",
    "# model_path = \"models/ppo_8x8_cnn_debug2/model_2600w\"\n",
    "model_path = \"models/cnn_selfplay/model_2915w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "sb3_model = PolicyModel.load(model_path)\n",
    "\n",
    "torch.save(sb3_model.policy.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffeb0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from model_deploy.policies import CustomCNN, ActorCriticPolicy\n",
    "from model_deploy.custom_feature_extractor import CustomCNN\n",
    "from model_deploy.policies import MaskableActorCriticPolicy\n",
    "\n",
    "\n",
    "backbone='cnn'\n",
    "# backbone='res_net'\n",
    "\n",
    "n_channels=3\n",
    "\n",
    "\n",
    "features_extractor_kwargs=dict(features_dim=256,\n",
    "                               backbone=backbone,\n",
    "                               net_arch=[128, 128, 256],\n",
    "#                                net_arch=[64, 128, 128],\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               is_batch_norm=True\n",
    "                               )\n",
    "\n",
    "observation_space=(n_channels, 8, 8)\n",
    "action_space = [observation_space[1]*observation_space[2]]\n",
    "\n",
    "policy_model = MaskableActorCriticPolicy(\n",
    "        observation_space=observation_space, \n",
    "        action_space=action_space, \n",
    "        net_arch=[256, 256],\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = features_extractor_kwargs,\n",
    "        share_features_extractor = True,\n",
    "    normalize_images=False\n",
    "\n",
    ")\n",
    "\n",
    "# # model_path = \"models/ppo_8x8_cnn/model\"\n",
    "# model_path = \"models/cnn_selfplay/model_760w\"\n",
    "# # model_path = \"models/model_460w\"\n",
    "\n",
    "# # model_path = \"models/model\"\n",
    "# state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "# policy_model.load_state_dict(torch.load(state_dict_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19a7cd79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskableActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU()\n",
       "        (9): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU()\n",
       "        (9): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU()\n",
       "        (9): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2e12b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.archive_path: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 8.99997344e-01, 8.09994953e-01, 7.28992802e-01,\n",
       "       6.56090865e-01, 5.90479123e-01, 5.31428554e-01, 4.78283042e-01,\n",
       "       4.30452082e-01, 3.87404218e-01, 3.48661140e-01, 3.13792369e-01,\n",
       "       2.82410476e-01, 2.54166772e-01, 2.28747439e-01, 2.05870039e-01,\n",
       "       1.85280379e-01, 1.66749685e-01, 1.50072060e-01, 1.35062198e-01,\n",
       "       1.21553322e-01, 1.09395333e-01, 9.84531439e-02, 8.86051733e-02,\n",
       "       7.97419997e-02, 7.17651436e-02, 6.45859730e-02, 5.81247195e-02,\n",
       "       5.23095913e-02, 4.70759760e-02, 4.23657222e-02, 3.81264937e-02,\n",
       "       3.43111882e-02, 3.08774131e-02, 2.77870156e-02, 2.50056578e-02,\n",
       "       2.25024358e-02, 2.02495360e-02, 1.82219262e-02, 1.63970774e-02,\n",
       "       1.47547134e-02, 1.32765859e-02, 1.19462711e-02, 1.07489878e-02,\n",
       "       9.67143279e-03, 8.70163330e-03, 7.82881376e-03, 7.04327617e-03,\n",
       "       6.33629234e-03, 5.70000690e-03, 5.12735000e-03, 4.61195879e-03,\n",
       "       4.14810670e-03, 3.73063982e-03, 3.35491963e-03, 3.01677145e-03,\n",
       "       2.71243810e-03, 2.43853808e-03, 2.19202806e-03, 1.97016904e-03,\n",
       "       1.77049593e-03, 1.59079012e-03, 1.42905490e-03, 1.28349320e-03,\n",
       "       1.15248767e-03, 1.03458269e-03, 9.28468213e-04, 8.32965182e-04,\n",
       "       7.47012453e-04, 6.69654997e-04, 6.00033287e-04, 5.37373748e-04,\n",
       "       4.80980163e-04, 4.30225936e-04, 3.84547132e-04, 3.43436208e-04,\n",
       "       3.06436377e-04, 2.73136529e-04, 2.43166666e-04, 2.16193789e-04,\n",
       "       1.91918199e-04, 1.70070169e-04, 1.50406942e-04, 1.32710037e-04,\n",
       "       1.16782823e-04, 1.02448330e-04, 8.95472866e-05, 7.79363475e-05,\n",
       "       6.74865023e-05, 5.80816417e-05, 4.96172671e-05, 4.19993299e-05,\n",
       "       3.51431865e-05, 2.89726574e-05, 2.34191812e-05, 1.84210526e-05,\n",
       "       1.39227369e-05, 9.87425281e-06, 6.23061708e-06, 2.95134493e-06])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reversi_model_train import ReversiModelTrain\n",
    "\n",
    "obj = ReversiModelTrain(opponent_window_size=100,opponent_prob_decay_rate=0.9)\n",
    "obj.opponent_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9afdced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj._get_next_opponent_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf479d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00028460767526957515"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.96**200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48027438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.49152542372883"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.0059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4692a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=True\n",
    "y=not x\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3fb93428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011529215046068483"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.8**20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c3a6e",
   "metadata": {},
   "source": [
    "### model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c29a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- round:0 --------\n",
      "total_win:1, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:1 --------\n",
      "total_win:2, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:2 --------\n",
      "total_win:3, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:3 --------\n",
      "total_win:4, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:4 --------\n",
      "total_win:5, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:5 --------\n",
      "total_win:6, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:6 --------\n",
      "total_win:7, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:7 --------\n",
      "total_win:8, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:8 --------\n",
      "total_win:9, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:9 --------\n",
      "total_win:10, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:10 --------\n",
      "total_win:11, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:11 --------\n",
      "total_win:12, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:12 --------\n",
      "total_win:13, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:13 --------\n",
      "total_win:14, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:14 --------\n",
      "total_win:15, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:15 --------\n",
      "total_win:16, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:16 --------\n",
      "total_win:17, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:17 --------\n",
      "total_win:18, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:18 --------\n",
      "total_win:19, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:19 --------\n",
      "total_win:20, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:20 --------\n",
      "total_win:21, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:21 --------\n",
      "total_win:22, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:22 --------\n",
      "total_win:23, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:23 --------\n",
      "total_win:24, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:24 --------\n",
      "total_win:25, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:25 --------\n",
      "total_win:26, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:26 --------\n",
      "total_win:27, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:27 --------\n",
      "total_win:28, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:28 --------\n",
      "total_win:29, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:29 --------\n",
      "total_win:30, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:30 --------\n",
      "total_win:31, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:31 --------\n",
      "total_win:32, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:32 --------\n",
      "total_win:33, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:33 --------\n",
      "total_win:34, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:34 --------\n",
      "total_win:35, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:35 --------\n",
      "total_win:36, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:36 --------\n",
      "total_win:37, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:37 --------\n",
      "total_win:38, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:38 --------\n",
      "total_win:39, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:39 --------\n",
      "total_win:40, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:40 --------\n",
      "total_win:41, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:41 --------\n",
      "total_win:42, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:42 --------\n",
      "total_win:43, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:43 --------\n",
      "total_win:44, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:44 --------\n",
      "total_win:45, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:45 --------\n",
      "total_win:46, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:46 --------\n",
      "total_win:47, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:47 --------\n",
      "total_win:48, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:48 --------\n",
      "total_win:49, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:49 --------\n",
      "total_win:50, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:50 --------\n",
      "total_win:51, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:51 --------\n",
      "total_win:52, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:52 --------\n",
      "total_win:53, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:53 --------\n",
      "total_win:54, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:54 --------\n",
      "total_win:55, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:55 --------\n",
      "total_win:56, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:56 --------\n",
      "total_win:57, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:57 --------\n",
      "total_win:58, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:58 --------\n",
      "total_win:59, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:59 --------\n",
      "total_win:60, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:60 --------\n",
      "total_win:61, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:61 --------\n",
      "total_win:62, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:62 --------\n",
      "total_win:63, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:63 --------\n",
      "total_win:64, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:64 --------\n",
      "total_win:65, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:65 --------\n",
      "total_win:66, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:66 --------\n",
      "total_win:67, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:67 --------\n",
      "total_win:68, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:68 --------\n",
      "total_win:69, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:69 --------\n",
      "total_win:70, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:70 --------\n",
      "total_win:71, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:71 --------\n",
      "total_win:72, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:72 --------\n",
      "total_win:73, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:73 --------\n",
      "total_win:74, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:74 --------\n",
      "total_win:75, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:75 --------\n",
      "total_win:76, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:76 --------\n",
      "total_win:77, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:77 --------\n",
      "total_win:78, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:78 --------\n",
      "total_win:79, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:79 --------\n",
      "total_win:80, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:80 --------\n",
      "total_win:81, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:81 --------\n",
      "total_win:82, total_failure: 0, total_equal:0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-08be24cbe4c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m game_play(model_path, \n\u001b[0m\u001b[0;32m     24\u001b[0m           \u001b[0mopponent_model_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m           \u001b[0mn_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\mygithub\\RL-demo\\reversi\\model_test.py\u001b[0m in \u001b[0;36mgame_play\u001b[1;34m(model_path, opponent_model_path, n_channels, max_round, board_size, verbose, deterministic)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;31m#     print(f\"---- round:{n} --------\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m#     print(f\"action: {action}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\mygithub\\RL-demo\\reversi\\gym_reversi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"self.observation:\\n {self.observation}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0mopponent_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopponent_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayer_color\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_action_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopponent_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayer_color\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# 设置对手落子位置\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\mygithub\\RL-demo\\reversi\\gym_reversi.py\u001b[0m in \u001b[0;36mmodel_policy\u001b[1;34m(observation, player_color, action_masks)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmodel_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# 注： 用对手作为陪练时也要设置 deterministic=False， 否则会形成固定走法\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_policy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\sb3_contrib\\ppo_mask\\ppo_mask.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, observation, state, episode_start, deterministic, action_masks)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mused\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\sb3_contrib\\common\\maskable\\policies.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, observation, state, episode_start, deterministic, action_masks)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_training_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorized_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mobs_to_tensor\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[0mobs_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs_as_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobs_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorized_env\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\utils.py\u001b[0m in \u001b[0;36mobs_as_tensor\u001b[1;34m(obs, device)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \"\"\"\n\u001b[0;32m    482\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_obs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from model_test import game_play\n",
    "\n",
    "# model_path = \".\\models\\cnn_selfplay\\model_20w\"\n",
    "opponent_model_path=\"random\"\n",
    "opponent_model_path = \".\\models\\ppo_8x8_cnn_debug2\\model_2600w\"\n",
    "# # opponent_model_path = \".\\models\\ppo_8x8_cnn_debug1\\model_1000w\"\n",
    "# opponent_model_path = \".\\models\\ppo_8x8_resnet_lr_decay\\model_1000w\"\n",
    "opponent_model_path = \".\\models\\cnn_selfplay\\model_2275w\"\n",
    "\n",
    "# model_path = \".\\models\\ppo_8x8_cnn_debug2\\model_2600w\"\n",
    "# model_path = \".\\models\\ppo_8x8_resnet_lr_decay\\model_1000w\"\n",
    "\n",
    "model_path = \".\\models\\cnn_selfplay\\model_2915w\"\n",
    "\n",
    "max_round=100\n",
    "\n",
    "n_channels=3\n",
    "board_size=8\n",
    "\n",
    "verbose=0\n",
    "deterministic=True\n",
    "\n",
    "game_play(model_path, \n",
    "          opponent_model_path, \n",
    "          n_channels=n_channels, \n",
    "          max_round=max_round, \n",
    "          board_size=board_size, \n",
    "          verbose=verbose,\n",
    "          deterministic=deterministic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa92035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ba6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from model_deploy.policies import CustomCNN, ActorCriticPolicy\n",
    "from model_deploy.custom_feature_extractor import CustomCNN\n",
    "from model_deploy.policies import MaskableActorCriticPolicy\n",
    "\n",
    "\n",
    "backbone='cnn'\n",
    "# backbone='res_net'\n",
    "\n",
    "n_channels=3\n",
    "\n",
    "\n",
    "features_extractor_kwargs=dict(features_dim=256,\n",
    "                               backbone=backbone,\n",
    "                               net_arch=[128, 128, 256],\n",
    "#                                net_arch=[64, 128, 128],\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               is_batch_norm=True\n",
    "                               )\n",
    "\n",
    "observation_space=(n_channels, 8, 8)\n",
    "action_space = [observation_space[1]*observation_space[2]]\n",
    "\n",
    "policy_model = MaskableActorCriticPolicy(\n",
    "        observation_space=observation_space, \n",
    "        action_space=action_space, \n",
    "        net_arch=[256, 256],\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = features_extractor_kwargs,\n",
    "        share_features_extractor = True,\n",
    "    normalize_images=False\n",
    "\n",
    ")\n",
    "\n",
    "policy_model2 = MaskableActorCriticPolicy(\n",
    "        observation_space=observation_space, \n",
    "        action_space=action_space, \n",
    "        net_arch=[256, 256],\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = features_extractor_kwargs,\n",
    "        share_features_extractor = True,\n",
    "    normalize_images=False\n",
    "\n",
    ")\n",
    "# model_path = \"models/ppo_8x8_cnn/model\"\n",
    "# model_path = \"models/cnn_selfplay/model_760w\"\n",
    "# model_path = \"models/colab/resnet/model_200w\"\n",
    "\n",
    "# # model_path = \"models/model\"\n",
    "# state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "# policy_model.load_state_dict(torch.load(state_dict_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f876d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340dd77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- round:0 --------\n",
      "total_win:1, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:1 --------\n",
      "total_win:2, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:2 --------\n",
      "total_win:3, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:3 --------\n",
      "total_win:4, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:4 --------\n",
      "total_win:5, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:5 --------\n",
      "total_win:6, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:6 --------\n",
      "total_win:7, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:7 --------\n",
      "total_win:8, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:8 --------\n",
      "total_win:9, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:9 --------\n",
      "total_win:10, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:10 --------\n",
      "total_win:11, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:11 --------\n",
      "total_win:12, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:12 --------\n",
      "total_win:13, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:13 --------\n",
      "total_win:14, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:14 --------\n",
      "total_win:15, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:15 --------\n",
      "total_win:16, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:16 --------\n",
      "total_win:17, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:17 --------\n",
      "total_win:18, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:18 --------\n",
      "total_win:19, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:19 --------\n",
      "total_win:20, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:20 --------\n",
      "total_win:21, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:21 --------\n",
      "total_win:22, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:22 --------\n",
      "total_win:23, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:23 --------\n",
      "total_win:24, total_failure: 0, total_equal:0\n",
      "\n",
      "---- round:24 --------\n",
      "total_win:24, total_failure: 0, total_equal:1\n",
      "\n",
      "---- round:25 --------\n",
      "total_win:25, total_failure: 0, total_equal:1\n",
      "\n",
      "---- round:26 --------\n",
      "total_win:26, total_failure: 0, total_equal:1\n",
      "\n",
      "---- round:27 --------\n",
      "total_win:27, total_failure: 0, total_equal:1\n",
      "\n",
      "---- round:28 --------\n",
      "total_win:28, total_failure: 0, total_equal:1\n",
      "\n",
      "---- round:29 --------\n",
      "total_win:29, total_failure: 0, total_equal:1\n",
      "\n",
      "---- round:30 --------\n",
      "total_win:29, total_failure: 1, total_equal:1\n",
      "\n",
      "---- round:31 --------\n",
      "total_win:29, total_failure: 2, total_equal:1\n",
      "\n",
      "---- round:32 --------\n",
      "total_win:30, total_failure: 2, total_equal:1\n",
      "\n",
      "---- round:33 --------\n",
      "total_win:31, total_failure: 2, total_equal:1\n",
      "\n",
      "---- round:34 --------\n",
      "total_win:31, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:35 --------\n",
      "total_win:32, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:36 --------\n",
      "total_win:33, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:37 --------\n",
      "total_win:34, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:38 --------\n",
      "total_win:35, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:39 --------\n",
      "total_win:36, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:40 --------\n",
      "total_win:37, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:41 --------\n",
      "total_win:38, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:42 --------\n",
      "total_win:39, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:43 --------\n",
      "total_win:40, total_failure: 3, total_equal:1\n",
      "\n",
      "---- round:44 --------\n",
      "total_win:40, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:45 --------\n",
      "total_win:41, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:46 --------\n",
      "total_win:42, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:47 --------\n",
      "total_win:43, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:48 --------\n",
      "total_win:44, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:49 --------\n",
      "total_win:45, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:50 --------\n",
      "total_win:46, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:51 --------\n",
      "total_win:47, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:52 --------\n",
      "total_win:48, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:53 --------\n",
      "total_win:49, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:54 --------\n",
      "total_win:50, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:55 --------\n",
      "total_win:51, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:56 --------\n",
      "total_win:52, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:57 --------\n",
      "total_win:53, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:58 --------\n",
      "total_win:54, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:59 --------\n",
      "total_win:55, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:60 --------\n",
      "total_win:56, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:61 --------\n",
      "total_win:57, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:62 --------\n",
      "total_win:58, total_failure: 3, total_equal:2\n",
      "\n",
      "---- round:63 --------\n",
      "total_win:58, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:64 --------\n",
      "total_win:59, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:65 --------\n",
      "total_win:60, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:66 --------\n",
      "total_win:61, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:67 --------\n",
      "total_win:62, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:68 --------\n",
      "total_win:63, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:69 --------\n",
      "total_win:64, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:70 --------\n",
      "total_win:65, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:71 --------\n",
      "total_win:66, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:72 --------\n",
      "total_win:67, total_failure: 3, total_equal:3\n",
      "\n",
      "---- round:73 --------\n",
      "total_win:67, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:74 --------\n",
      "total_win:68, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:75 --------\n",
      "total_win:69, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:76 --------\n",
      "total_win:70, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:77 --------\n",
      "total_win:71, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:78 --------\n",
      "total_win:72, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:79 --------\n",
      "total_win:73, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:80 --------\n",
      "total_win:74, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:81 --------\n",
      "total_win:75, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:82 --------\n",
      "total_win:76, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:83 --------\n",
      "total_win:77, total_failure: 3, total_equal:4\n",
      "\n",
      "---- round:84 --------\n",
      "total_win:77, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:85 --------\n",
      "total_win:78, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:86 --------\n",
      "total_win:79, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:87 --------\n",
      "total_win:80, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:88 --------\n",
      "total_win:81, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:89 --------\n",
      "total_win:82, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:90 --------\n",
      "total_win:83, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:91 --------\n",
      "total_win:84, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:92 --------\n",
      "total_win:85, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:93 --------\n",
      "total_win:86, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:94 --------\n",
      "total_win:87, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:95 --------\n",
      "total_win:88, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:96 --------\n",
      "total_win:89, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:97 --------\n",
      "total_win:90, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:98 --------\n",
      "total_win:91, total_failure: 4, total_equal:4\n",
      "\n",
      "---- round:99 --------\n",
      "total_win:92, total_failure: 4, total_equal:4\n",
      "\n",
      "win: 92, failure: 4, equal_cnt: 4, win_rate: 0.9583\n",
      "\n",
      " win_rate: 0.9583\n",
      "\n",
      "total time: 44.81306076049805\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from gym_reversi import ReversiEnv\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "# PolicyModel = PPO\n",
    "PolicyModel = MaskablePPO\n",
    "\n",
    "\n",
    "opponent_model=\"random\"\n",
    "\n",
    "# # opponent_model_path = \".\\models\\ppo_8x8_cnn_debug2\\model_2600w\"\n",
    "# opponent_model_path = \".\\models\\cnn_selfplay\\model_1200w\"\n",
    "# opponent_model = PolicyModel.load(opponent_model_path)\n",
    "\n",
    "# state_dict_model_path = \"models/colab/resnet/model_300w_state_dict.pt\"\n",
    "# policy_model2.load_state_dict(torch.load(state_dict_model_path))\n",
    "\n",
    "# model_path = \".\\models\\ppo_8x8_resnet_lr_decay\\model_1000w\"\n",
    "# model = PolicyModel.load(model_path)\n",
    "\n",
    "# state_dict_model_path = \"models/ppo_8x8_cnn_debug2/model_2600w_state_dict.pt\"\n",
    "# state_dict_model_path = \"models/colab/resnet/model_215w_state_dict.pt\"\n",
    "state_dict_model_path = \"models/cnn_selfplay/model_2915w_state_dict.pt\"\n",
    "\n",
    "policy_model.load_state_dict(torch.load(state_dict_model_path))\n",
    "\n",
    "# policy_model.load_state_dict(torch.load(\"models/cnn_selfplay/model_760w_state_dict.pt\"))\n",
    "model = policy_model\n",
    "\n",
    "# model = opponent_model\n",
    "# opponent_model = policy_model\n",
    "\n",
    "\n",
    "max_round=100\n",
    "\n",
    "n_channels=3\n",
    "board_size=8\n",
    "verbose=0\n",
    "\n",
    "deterministic = True\n",
    "is_train=(not deterministic)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "n = 0\n",
    "_win = 0\n",
    "_failure = 0\n",
    "_equal = 0\n",
    "\n",
    "env = ReversiEnv(opponent=opponent_model, n_channels=n_channels, is_train=is_train,\n",
    "                 board_size=board_size, verbose=verbose)\n",
    "\n",
    "obs, info = env.reset()\n",
    "while n < max_round:\n",
    "    possible_actions = get_possible_actions(obs, player_color=env.player_color)\n",
    "    action_masks = valid_action_mask(board_size=board_size, possible_actions=possible_actions)\n",
    "    action, _states = model.predict(obs, deterministic=deterministic, action_masks=action_masks)\n",
    "    action = int(action)\n",
    "    obs, rewards, dones, truncated, info = env.step(action)\n",
    "    #     print(f\"---- round:{n} --------\")\n",
    "    #     print(f\"action: {action}\")\n",
    "    #     env.render(\"human\")\n",
    "    if dones:\n",
    "        print(f\"---- round:{n} --------\")\n",
    "        #         env.render(\"human\")\n",
    "        obs, info = env.reset()\n",
    "        n += 1\n",
    "        if rewards > 0:\n",
    "            _win += 1\n",
    "        elif rewards < 0:\n",
    "            _failure += 1\n",
    "        else:\n",
    "            _equal += 1\n",
    "        print(f\"total_win:{_win}, total_failure: {_failure}, total_equal:{_equal}\\n\")\n",
    "\n",
    "_win_rate = round(_win/(_win + _failure) * 10000)/10000\n",
    "print(f\"win: {_win}, failure: {_failure}, equal_cnt: {_equal}, win_rate: {_win_rate}\\n\")\n",
    "print(f\" win_rate: {_win_rate}\\n\")\n",
    "print(f\"total time: {time.time() - t0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "win: [483, 469], failure: [13, 24], equal_cnt: [4, 7], win_rate: [0.9738, 0.9513]\n",
    "total win: 952, failure: 37, equal_cnt: 11, win_rate: 0.9626\n",
    "train time: 477.33438515663147"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84461556",
   "metadata": {},
   "source": [
    "### 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed063b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21bb1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym_reversi import ReversiEnv\n",
    "\n",
    "def get_possible_actions(board, player_color):\n",
    "    actions = []\n",
    "    d = board.shape[-1]\n",
    "    opponent_color = 1 - player_color\n",
    "    for pos_x in range(d):\n",
    "        for pos_y in range(d):\n",
    "            if board[0, pos_x, pos_y] or board[1, pos_x, pos_y]:\n",
    "                continue\n",
    "            for dx in [-1, 0, 1]:\n",
    "                for dy in [-1, 0, 1]:\n",
    "                    if dx == 0 and dy == 0:\n",
    "                        continue\n",
    "                    nx = pos_x + dx\n",
    "                    ny = pos_y + dy\n",
    "                    n = 0\n",
    "                    if nx not in range(d) or ny not in range(d):\n",
    "                        continue\n",
    "                    while board[opponent_color, nx, ny] == 1:\n",
    "                        tmp_nx = nx + dx\n",
    "                        tmp_ny = ny + dy\n",
    "                        if tmp_nx not in range(d) or tmp_ny not in range(d):\n",
    "                            break\n",
    "                        n += 1\n",
    "                        nx += dx\n",
    "                        ny += dy\n",
    "                    if n > 0 and board[player_color, nx, ny] == 1:\n",
    "                        action = pos_x * d + pos_y\n",
    "                        if action not in actions:\n",
    "                            actions.append(action)\n",
    "    return actions\n",
    "\n",
    "def set_possible_actions_place(board, possible_actions, channel_index=2):\n",
    "    board[channel_index, :, :] = 0\n",
    "    # possible_actions = ReversiEnv.get_possible_actions(board, player_color)\n",
    "    possible_actions_coords = [ReversiEnv.action_to_coordinate(board, _action) for _action in possible_actions]\n",
    "    for pos_x, pos_y in possible_actions_coords:\n",
    "        board[channel_index, pos_x, pos_y] = 1\n",
    "    return board\n",
    "\n",
    "def get_test_observation(board_size=4, player_color=0):\n",
    "    # init board setting\n",
    "    N_CHANNELS = 4\n",
    "    # channels： 0: 黑棋位置， 1: 白棋位置， 2: 当前可合法落子位置，3：player 颜色\n",
    "    observation = np.zeros((N_CHANNELS, board_size, board_size), dtype=int)\n",
    "\n",
    "    observation[3, :, :] = player_color\n",
    "\n",
    "    centerL = int(board_size / 2 - 1)\n",
    "    centerR = int(board_size / 2)\n",
    "    # self.observation[2, :, :] = 1\n",
    "    # self.observation[2, (centerL) : (centerR + 1), (centerL) : (centerR + 1)] = 0\n",
    "    observation[0, centerR, centerL] = 1\n",
    "    observation[0, centerL, centerR] = 1\n",
    "    observation[1, centerL, centerL] = 1\n",
    "    observation[1, centerR, centerR] = 1\n",
    "    possible_actions = get_possible_actions(observation, player_color)\n",
    "\n",
    "    # 设置主玩家合法位置\n",
    "    set_possible_actions_place(observation, possible_actions)\n",
    "\n",
    "    return observation\n",
    "\n",
    "\n",
    "def action_to_coordinate(board, action):\n",
    "    return action // board.shape[-1], action % board.shape[-1]\n",
    "\n",
    "\n",
    "def valid_action_mask(board_size=8, possible_actions=[]):\n",
    "    valid_actions = np.zeros((board_size**2, ), dtype=np.uint8)\n",
    "    for idx in possible_actions:\n",
    "        valid_actions[idx] = 1\n",
    "    return valid_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8337b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3165f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "# PolicyModel = PPO\n",
    "PolicyModel = MaskablePPO\n",
    "\n",
    "model_path = \"models/ppo_8x8_backbone/model_80w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "sb3_model = PolicyModel.load(model_path)\n",
    "\n",
    "torch.save(sb3_model.policy.state_dict(), state_dict_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf16963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskableActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (net): MyResNet(\n",
       "      (resnet_block): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (net): MyResNet(\n",
       "      (resnet_block): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (net): MyResNet(\n",
       "      (resnet_block): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb3_model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc055898",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features_extractor.net.resnet_block.0.conv1.weight', 'features_extractor.net.resnet_block.0.bn1.weight', 'features_extractor.net.resnet_block.0.bn1.bias', 'features_extractor.net.resnet_block.0.bn1.running_mean', 'features_extractor.net.resnet_block.0.bn1.running_var', 'features_extractor.net.resnet_block.0.bn1.num_batches_tracked', 'features_extractor.net.resnet_block.0.conv2.weight', 'features_extractor.net.resnet_block.0.bn2.weight', 'features_extractor.net.resnet_block.0.bn2.bias', 'features_extractor.net.resnet_block.0.bn2.running_mean', 'features_extractor.net.resnet_block.0.bn2.running_var', 'features_extractor.net.resnet_block.0.bn2.num_batches_tracked', 'features_extractor.net.resnet_block.0.downsample.0.weight', 'features_extractor.net.resnet_block.0.downsample.1.weight', 'features_extractor.net.resnet_block.0.downsample.1.bias', 'features_extractor.net.resnet_block.0.downsample.1.running_mean', 'features_extractor.net.resnet_block.0.downsample.1.running_var', 'features_extractor.net.resnet_block.0.downsample.1.num_batches_tracked', 'features_extractor.net.resnet_block.1.conv1.weight', 'features_extractor.net.resnet_block.1.bn1.weight', 'features_extractor.net.resnet_block.1.bn1.bias', 'features_extractor.net.resnet_block.1.bn1.running_mean', 'features_extractor.net.resnet_block.1.bn1.running_var', 'features_extractor.net.resnet_block.1.bn1.num_batches_tracked', 'features_extractor.net.resnet_block.1.conv2.weight', 'features_extractor.net.resnet_block.1.bn2.weight', 'features_extractor.net.resnet_block.1.bn2.bias', 'features_extractor.net.resnet_block.1.bn2.running_mean', 'features_extractor.net.resnet_block.1.bn2.running_var', 'features_extractor.net.resnet_block.1.bn2.num_batches_tracked', 'features_extractor.net.resnet_block.1.downsample.0.weight', 'features_extractor.net.resnet_block.1.downsample.1.weight', 'features_extractor.net.resnet_block.1.downsample.1.bias', 'features_extractor.net.resnet_block.1.downsample.1.running_mean', 'features_extractor.net.resnet_block.1.downsample.1.running_var', 'features_extractor.net.resnet_block.1.downsample.1.num_batches_tracked', 'features_extractor.net.resnet_block.2.conv1.weight', 'features_extractor.net.resnet_block.2.bn1.weight', 'features_extractor.net.resnet_block.2.bn1.bias', 'features_extractor.net.resnet_block.2.bn1.running_mean', 'features_extractor.net.resnet_block.2.bn1.running_var', 'features_extractor.net.resnet_block.2.bn1.num_batches_tracked', 'features_extractor.net.resnet_block.2.conv2.weight', 'features_extractor.net.resnet_block.2.bn2.weight', 'features_extractor.net.resnet_block.2.bn2.bias', 'features_extractor.net.resnet_block.2.bn2.running_mean', 'features_extractor.net.resnet_block.2.bn2.running_var', 'features_extractor.net.resnet_block.2.bn2.num_batches_tracked', 'features_extractor.net.conv1.weight', 'features_extractor.net.bn1.weight', 'features_extractor.net.bn1.bias', 'features_extractor.net.bn1.running_mean', 'features_extractor.net.bn1.running_var', 'features_extractor.net.bn1.num_batches_tracked', 'features_extractor.net.fc.weight', 'features_extractor.net.fc.bias', 'features_extractor.linear.0.weight', 'features_extractor.linear.0.bias', 'pi_features_extractor.net.resnet_block.0.conv1.weight', 'pi_features_extractor.net.resnet_block.0.bn1.weight', 'pi_features_extractor.net.resnet_block.0.bn1.bias', 'pi_features_extractor.net.resnet_block.0.bn1.running_mean', 'pi_features_extractor.net.resnet_block.0.bn1.running_var', 'pi_features_extractor.net.resnet_block.0.bn1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.0.conv2.weight', 'pi_features_extractor.net.resnet_block.0.bn2.weight', 'pi_features_extractor.net.resnet_block.0.bn2.bias', 'pi_features_extractor.net.resnet_block.0.bn2.running_mean', 'pi_features_extractor.net.resnet_block.0.bn2.running_var', 'pi_features_extractor.net.resnet_block.0.bn2.num_batches_tracked', 'pi_features_extractor.net.resnet_block.0.downsample.0.weight', 'pi_features_extractor.net.resnet_block.0.downsample.1.weight', 'pi_features_extractor.net.resnet_block.0.downsample.1.bias', 'pi_features_extractor.net.resnet_block.0.downsample.1.running_mean', 'pi_features_extractor.net.resnet_block.0.downsample.1.running_var', 'pi_features_extractor.net.resnet_block.0.downsample.1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.1.conv1.weight', 'pi_features_extractor.net.resnet_block.1.bn1.weight', 'pi_features_extractor.net.resnet_block.1.bn1.bias', 'pi_features_extractor.net.resnet_block.1.bn1.running_mean', 'pi_features_extractor.net.resnet_block.1.bn1.running_var', 'pi_features_extractor.net.resnet_block.1.bn1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.1.conv2.weight', 'pi_features_extractor.net.resnet_block.1.bn2.weight', 'pi_features_extractor.net.resnet_block.1.bn2.bias', 'pi_features_extractor.net.resnet_block.1.bn2.running_mean', 'pi_features_extractor.net.resnet_block.1.bn2.running_var', 'pi_features_extractor.net.resnet_block.1.bn2.num_batches_tracked', 'pi_features_extractor.net.resnet_block.1.downsample.0.weight', 'pi_features_extractor.net.resnet_block.1.downsample.1.weight', 'pi_features_extractor.net.resnet_block.1.downsample.1.bias', 'pi_features_extractor.net.resnet_block.1.downsample.1.running_mean', 'pi_features_extractor.net.resnet_block.1.downsample.1.running_var', 'pi_features_extractor.net.resnet_block.1.downsample.1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.2.conv1.weight', 'pi_features_extractor.net.resnet_block.2.bn1.weight', 'pi_features_extractor.net.resnet_block.2.bn1.bias', 'pi_features_extractor.net.resnet_block.2.bn1.running_mean', 'pi_features_extractor.net.resnet_block.2.bn1.running_var', 'pi_features_extractor.net.resnet_block.2.bn1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.2.conv2.weight', 'pi_features_extractor.net.resnet_block.2.bn2.weight', 'pi_features_extractor.net.resnet_block.2.bn2.bias', 'pi_features_extractor.net.resnet_block.2.bn2.running_mean', 'pi_features_extractor.net.resnet_block.2.bn2.running_var', 'pi_features_extractor.net.resnet_block.2.bn2.num_batches_tracked', 'pi_features_extractor.net.conv1.weight', 'pi_features_extractor.net.bn1.weight', 'pi_features_extractor.net.bn1.bias', 'pi_features_extractor.net.bn1.running_mean', 'pi_features_extractor.net.bn1.running_var', 'pi_features_extractor.net.bn1.num_batches_tracked', 'pi_features_extractor.net.fc.weight', 'pi_features_extractor.net.fc.bias', 'pi_features_extractor.linear.0.weight', 'pi_features_extractor.linear.0.bias', 'vf_features_extractor.net.resnet_block.0.conv1.weight', 'vf_features_extractor.net.resnet_block.0.bn1.weight', 'vf_features_extractor.net.resnet_block.0.bn1.bias', 'vf_features_extractor.net.resnet_block.0.bn1.running_mean', 'vf_features_extractor.net.resnet_block.0.bn1.running_var', 'vf_features_extractor.net.resnet_block.0.bn1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.0.conv2.weight', 'vf_features_extractor.net.resnet_block.0.bn2.weight', 'vf_features_extractor.net.resnet_block.0.bn2.bias', 'vf_features_extractor.net.resnet_block.0.bn2.running_mean', 'vf_features_extractor.net.resnet_block.0.bn2.running_var', 'vf_features_extractor.net.resnet_block.0.bn2.num_batches_tracked', 'vf_features_extractor.net.resnet_block.0.downsample.0.weight', 'vf_features_extractor.net.resnet_block.0.downsample.1.weight', 'vf_features_extractor.net.resnet_block.0.downsample.1.bias', 'vf_features_extractor.net.resnet_block.0.downsample.1.running_mean', 'vf_features_extractor.net.resnet_block.0.downsample.1.running_var', 'vf_features_extractor.net.resnet_block.0.downsample.1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.1.conv1.weight', 'vf_features_extractor.net.resnet_block.1.bn1.weight', 'vf_features_extractor.net.resnet_block.1.bn1.bias', 'vf_features_extractor.net.resnet_block.1.bn1.running_mean', 'vf_features_extractor.net.resnet_block.1.bn1.running_var', 'vf_features_extractor.net.resnet_block.1.bn1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.1.conv2.weight', 'vf_features_extractor.net.resnet_block.1.bn2.weight', 'vf_features_extractor.net.resnet_block.1.bn2.bias', 'vf_features_extractor.net.resnet_block.1.bn2.running_mean', 'vf_features_extractor.net.resnet_block.1.bn2.running_var', 'vf_features_extractor.net.resnet_block.1.bn2.num_batches_tracked', 'vf_features_extractor.net.resnet_block.1.downsample.0.weight', 'vf_features_extractor.net.resnet_block.1.downsample.1.weight', 'vf_features_extractor.net.resnet_block.1.downsample.1.bias', 'vf_features_extractor.net.resnet_block.1.downsample.1.running_mean', 'vf_features_extractor.net.resnet_block.1.downsample.1.running_var', 'vf_features_extractor.net.resnet_block.1.downsample.1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.2.conv1.weight', 'vf_features_extractor.net.resnet_block.2.bn1.weight', 'vf_features_extractor.net.resnet_block.2.bn1.bias', 'vf_features_extractor.net.resnet_block.2.bn1.running_mean', 'vf_features_extractor.net.resnet_block.2.bn1.running_var', 'vf_features_extractor.net.resnet_block.2.bn1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.2.conv2.weight', 'vf_features_extractor.net.resnet_block.2.bn2.weight', 'vf_features_extractor.net.resnet_block.2.bn2.bias', 'vf_features_extractor.net.resnet_block.2.bn2.running_mean', 'vf_features_extractor.net.resnet_block.2.bn2.running_var', 'vf_features_extractor.net.resnet_block.2.bn2.num_batches_tracked', 'vf_features_extractor.net.conv1.weight', 'vf_features_extractor.net.bn1.weight', 'vf_features_extractor.net.bn1.bias', 'vf_features_extractor.net.bn1.running_mean', 'vf_features_extractor.net.bn1.running_var', 'vf_features_extractor.net.bn1.num_batches_tracked', 'vf_features_extractor.net.fc.weight', 'vf_features_extractor.net.fc.bias', 'vf_features_extractor.linear.0.weight', 'vf_features_extractor.linear.0.bias', 'mlp_extractor.policy_net.0.weight', 'mlp_extractor.policy_net.0.bias', 'mlp_extractor.policy_net.2.weight', 'mlp_extractor.policy_net.2.bias', 'mlp_extractor.value_net.0.weight', 'mlp_extractor.value_net.0.bias', 'mlp_extractor.value_net.2.weight', 'mlp_extractor.value_net.2.bias', 'action_net.weight', 'action_net.bias', 'value_net.weight', 'value_net.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb3_model.policy.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b0b56a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=256, out_features=16, bias=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.action_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862d219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fc33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from model_deploy.policies import CustomCNN, ActorCriticPolicy\n",
    "from model_deploy.custom_feature_extractor import CustomCNN\n",
    "from model_deploy.policies import MaskableActorCriticPolicy\n",
    "\n",
    "def build_model(state_dict_path, features_extractor_kwargs, observation_space=(4,8,8)):\n",
    "\n",
    "    # features_extractor_kwargs=dict(features_dim=1024,\n",
    "    #                                net_arch=[64, 128, 256],\n",
    "    #                                # net_arch=[64, 128, 128],\n",
    "    #                                # net_arch=[32, 64, 128],\n",
    "    #                                kernel_size=3,\n",
    "    #                                stride=1,\n",
    "    #                                padding='same',\n",
    "    #                                is_batch_norm=False),\n",
    "\n",
    "    action_space = [observation_space[1]*observation_space[2]]\n",
    "\n",
    "    policy_model = MaskableActorCriticPolicy(\n",
    "                    observation_space = observation_space,\n",
    "                    action_space = action_space,\n",
    "                    net_arch=[256, 256],\n",
    "                    features_extractor_class = CustomCNN,\n",
    "                    features_extractor_kwargs = features_extractor_kwargs,\n",
    "                    normalize_images= False,\n",
    "    )\n",
    "\n",
    "    return policy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af5c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9321ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5da6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ppo_model = PPO.load(\"models/Reversi_ppo_4x4/model_100w\")\n",
    "\n",
    "# ## 保存模型\n",
    "# torch.save(ppo_model.policy, 'models/Reversi_ppo_4x4/model_100w.pth')\n",
    "\n",
    "# ## 读取模型\n",
    "# pth_model = torch.load('models/Reversi_ppo_4x4/model_100w.pth')\n",
    "\n",
    "observation = get_test_observation(board_size=8, player_color=0)\n",
    "# observation\n",
    "\n",
    "possible_actions = get_possible_actions(observation, player_color=0)\n",
    "\n",
    "action_masks = valid_action_mask(board_size=8, possible_actions=possible_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ecd92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 26, 37, 44]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5748f519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f57fffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(26, dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action, _states = sb3_model.predict(observation, deterministic=True, action_masks=action_masks)\n",
    "action\n",
    "# action_to_coordinate(observation, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78141b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(26, dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3d8b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskableActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25712a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e67ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# from model_deploy.policies import CustomCNN, ActorCriticPolicy\n",
    "from model_deploy.custom_feature_extractor import CustomCNN\n",
    "from model_deploy.policies import MaskableActorCriticPolicy\n",
    "\n",
    "\n",
    "# backbone='cnn'\n",
    "backbone='res_net'\n",
    "\n",
    "features_extractor_kwargs=dict(features_dim=256,\n",
    "                               backbone=backbone,\n",
    "#                                net_arch=[64, 128, 256],\n",
    "                               net_arch=[64, 128, 128],\n",
    "#                                net_arch=[32, 64, 128],\n",
    "#                                net_arch=[32, 64, 64],\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               is_batch_norm=False\n",
    "                               )\n",
    "\n",
    "observation_space=(4, 8, 8)\n",
    "action_space = [observation_space[1]*observation_space[2]]\n",
    "\n",
    "policy_model = MaskableActorCriticPolicy(\n",
    "        observation_space=observation_space, \n",
    "        action_space=action_space, \n",
    "        net_arch=[256, 256],\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = features_extractor_kwargs,\n",
    "        share_features_extractor = True,\n",
    "    normalize_images=False\n",
    "\n",
    ")\n",
    "\n",
    "# model_path = \"models/ppo_8x8_cnn/model\"\n",
    "model_path = \"models/ppo_8x8_backbone/model_440w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "\n",
    "# model_path = \"models/model\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "policy_model.load_state_dict(torch.load(state_dict_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9804e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action, _states = policy_model.predict(observation, deterministic=True, action_masks=action_masks)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b1bfd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "596f5f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b9f2b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]])),\n",
       "             ('features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100])),\n",
       "             ('features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]])),\n",
       "             ('features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148])),\n",
       "             ('features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]])),\n",
       "             ('features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527])),\n",
       "             ('features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]])),\n",
       "             ('features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03])),\n",
       "             ('pi_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]])),\n",
       "             ('pi_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100])),\n",
       "             ('pi_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]])),\n",
       "             ('pi_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148])),\n",
       "             ('pi_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]])),\n",
       "             ('pi_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527])),\n",
       "             ('pi_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]])),\n",
       "             ('pi_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03])),\n",
       "             ('vf_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]])),\n",
       "             ('vf_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100])),\n",
       "             ('vf_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]])),\n",
       "             ('vf_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148])),\n",
       "             ('vf_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]])),\n",
       "             ('vf_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527])),\n",
       "             ('vf_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]])),\n",
       "             ('vf_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03])),\n",
       "             ('mlp_extractor.policy_net.0.weight',\n",
       "              tensor([[ 0.0052, -0.0291, -0.1622,  ..., -0.0602,  0.0157, -0.1659],\n",
       "                      [ 0.2019, -0.0419, -0.0568,  ..., -0.0626,  0.1577,  0.0271],\n",
       "                      [-0.0572,  0.1457,  0.0097,  ..., -0.0697,  0.0149,  0.1527],\n",
       "                      ...,\n",
       "                      [ 0.1710, -0.0119, -0.0412,  ..., -0.0447, -0.0182, -0.2364],\n",
       "                      [ 0.0447,  0.1429,  0.0491,  ...,  0.0427, -0.1254, -0.0774],\n",
       "                      [ 0.0038, -0.0645,  0.0989,  ...,  0.0437,  0.0210,  0.1546]])),\n",
       "             ('mlp_extractor.policy_net.0.bias',\n",
       "              tensor([-3.7934e-02, -1.0120e-02, -1.7950e-02,  1.3979e-02, -8.9758e-03,\n",
       "                       9.3981e-03,  1.4142e-02, -1.4561e-02,  7.6285e-03, -7.7994e-04,\n",
       "                       3.3254e-02,  3.0155e-03, -5.0676e-03, -8.6990e-03, -6.2035e-03,\n",
       "                      -1.2432e-02,  2.6509e-02,  2.8312e-02, -1.0761e-02, -6.4396e-03,\n",
       "                      -2.3653e-02, -5.9161e-03, -1.6559e-03,  2.3093e-03,  2.1843e-02,\n",
       "                      -5.1557e-03,  3.7100e-02,  2.4642e-02, -2.5497e-02,  2.5407e-02,\n",
       "                       3.0578e-02,  2.9345e-02,  7.7088e-03, -1.1796e-02, -1.3831e-02,\n",
       "                      -2.3595e-02, -1.1430e-03, -1.2029e-02, -7.1556e-03,  1.3530e-02,\n",
       "                      -2.2087e-02, -5.5528e-03,  4.2695e-03,  2.3459e-04, -3.0454e-05,\n",
       "                      -2.4168e-02,  7.0001e-03, -2.1349e-02,  8.1098e-03,  2.3649e-04,\n",
       "                      -1.2144e-02, -1.6706e-02, -1.0958e-02, -2.8586e-03,  3.7588e-02,\n",
       "                      -8.2629e-03,  4.8411e-03, -8.2878e-03,  1.0644e-02,  5.4867e-03,\n",
       "                       6.1514e-03,  9.5967e-03,  1.0890e-02,  4.9025e-03,  1.5948e-02,\n",
       "                       2.1311e-02,  9.8605e-03, -6.4243e-03, -2.9398e-03, -3.6904e-03,\n",
       "                      -9.9446e-03,  1.9047e-02,  1.4092e-02,  2.4026e-03,  3.2092e-02,\n",
       "                      -1.5059e-02,  8.1860e-03,  2.6424e-02, -3.0271e-02,  3.8252e-02,\n",
       "                       1.3251e-02, -1.6951e-02,  5.3191e-03,  2.9410e-02, -2.0283e-02,\n",
       "                       2.5827e-02, -4.1000e-03, -1.0457e-02,  2.1510e-03,  1.4410e-02,\n",
       "                      -4.7814e-03,  3.4634e-03,  4.0821e-03,  2.1709e-02,  3.6088e-02,\n",
       "                       8.9005e-03,  1.4891e-02,  6.9741e-04, -1.8474e-02,  7.3035e-03,\n",
       "                       1.6245e-02, -3.5832e-02,  8.3168e-03, -1.0705e-02,  2.0325e-02,\n",
       "                       2.9341e-02, -3.1170e-02,  1.2995e-02,  1.0005e-02, -3.5040e-02,\n",
       "                       1.2313e-02, -1.4531e-02,  2.3488e-02,  8.1426e-03, -1.0364e-02,\n",
       "                       2.7742e-03, -3.1425e-02,  1.2838e-04, -1.4976e-02, -4.1408e-03,\n",
       "                       8.6572e-03,  1.7360e-02,  3.3624e-02,  1.0835e-02, -1.7576e-02,\n",
       "                      -1.2138e-02,  1.5603e-02, -1.0795e-02,  2.0145e-02, -2.9814e-03,\n",
       "                       1.9765e-03, -8.7999e-03, -6.0783e-03,  1.3500e-02, -3.3708e-02,\n",
       "                      -1.0044e-02,  1.5282e-02,  1.2506e-02,  1.2176e-02,  7.7159e-03,\n",
       "                       3.4869e-02,  1.3253e-02,  5.5851e-05,  1.8154e-03, -6.9276e-04,\n",
       "                      -1.5390e-02,  2.1272e-02,  1.5382e-02, -1.2867e-03, -1.2366e-02,\n",
       "                      -2.6879e-02, -2.3791e-04, -1.2761e-02, -1.2157e-02, -1.4863e-02,\n",
       "                       4.1211e-02, -3.5103e-03,  1.8319e-02, -4.5932e-03, -5.1984e-03,\n",
       "                       2.5223e-02,  6.9816e-03, -8.6695e-03,  1.1261e-02, -1.7240e-03,\n",
       "                      -6.5262e-04, -8.2426e-03, -3.1230e-03, -3.0566e-02,  2.8768e-02,\n",
       "                       1.2229e-02,  8.3468e-03,  2.0897e-03,  1.0116e-02,  1.9699e-03,\n",
       "                       2.2369e-03, -1.7555e-02, -4.4118e-02,  2.1739e-02, -4.9466e-02,\n",
       "                      -8.6298e-03, -4.1051e-02,  2.9664e-02,  1.9345e-02, -2.0059e-02,\n",
       "                       2.3699e-02, -3.7010e-02,  2.4064e-02, -3.7450e-03,  4.3794e-02,\n",
       "                       3.8838e-02,  8.5117e-03, -7.4019e-03,  2.0133e-02,  2.1669e-02,\n",
       "                      -1.1451e-02,  1.6833e-02, -1.3509e-02, -7.1325e-04,  1.1084e-02,\n",
       "                       2.7922e-02,  1.0219e-02, -7.6056e-05, -1.0354e-02, -2.5249e-02,\n",
       "                       1.2617e-02, -2.6633e-03,  3.5738e-03,  3.5735e-04,  1.8399e-02,\n",
       "                      -4.8047e-03,  4.1018e-03,  4.1222e-03,  1.7260e-02, -1.0157e-02,\n",
       "                      -1.2880e-02, -2.6215e-02, -2.7168e-02,  1.0103e-02,  1.7706e-02,\n",
       "                      -4.7546e-02,  9.3363e-03, -2.8084e-02, -1.0535e-02, -1.5182e-02,\n",
       "                      -1.3819e-02, -1.1448e-02, -6.4746e-03,  7.6021e-04,  1.2651e-02,\n",
       "                      -1.0050e-02,  2.2821e-02,  1.5586e-02, -2.1990e-02, -9.9179e-03,\n",
       "                      -1.3580e-02,  1.8374e-03, -1.4163e-02, -5.2409e-03, -1.2622e-02,\n",
       "                      -7.0958e-04,  2.5395e-02, -1.7106e-02,  1.8910e-02,  4.9914e-06,\n",
       "                       3.1792e-03, -1.6064e-02,  6.5150e-03, -1.2743e-03,  1.4860e-03,\n",
       "                       7.6464e-03, -1.0430e-02, -7.9494e-03,  7.8145e-04,  4.2292e-03,\n",
       "                      -1.3421e-02])),\n",
       "             ('mlp_extractor.policy_net.2.weight',\n",
       "              tensor([[ 0.0511,  0.0201, -0.1065,  ...,  0.1073, -0.1929,  0.0241],\n",
       "                      [-0.0182, -0.0378,  0.0256,  ...,  0.0010, -0.0474,  0.1143],\n",
       "                      [-0.1059, -0.0264,  0.0380,  ...,  0.0188,  0.0859, -0.0179],\n",
       "                      ...,\n",
       "                      [ 0.0793, -0.0118, -0.1422,  ...,  0.1023,  0.1145, -0.0365],\n",
       "                      [-0.2033,  0.0724, -0.0057,  ...,  0.1733,  0.0949,  0.0662],\n",
       "                      [-0.1075, -0.1196,  0.0106,  ..., -0.0087, -0.0097,  0.0297]])),\n",
       "             ('mlp_extractor.policy_net.2.bias',\n",
       "              tensor([ 5.8172e-03, -9.2728e-03, -1.5235e-02,  2.1914e-02, -1.1689e-02,\n",
       "                      -3.3092e-03,  3.9647e-03,  3.0486e-02, -1.0433e-03, -2.3171e-02,\n",
       "                      -3.3122e-02,  7.0034e-03,  2.3954e-02,  8.0406e-03,  2.2886e-02,\n",
       "                       4.0525e-02, -3.2603e-02,  1.2374e-02,  1.5371e-02,  1.8317e-02,\n",
       "                      -3.2269e-02,  3.0887e-03,  9.6856e-04, -4.9347e-03, -8.1643e-03,\n",
       "                      -6.9902e-03, -2.0729e-02, -1.7335e-02,  1.0368e-02,  4.6599e-02,\n",
       "                      -9.1468e-03,  6.8571e-03, -3.8949e-02, -2.3278e-02,  2.9535e-02,\n",
       "                       2.7574e-02, -2.5148e-02, -4.7471e-03, -3.7972e-03,  3.3504e-02,\n",
       "                       1.0143e-03,  1.5877e-02,  4.4178e-03, -3.8147e-04,  5.7864e-03,\n",
       "                       8.3002e-03, -4.5355e-03, -1.7833e-03,  5.7902e-03, -3.3542e-02,\n",
       "                      -4.1374e-02, -4.3449e-03,  2.2690e-02,  4.9732e-02, -3.6212e-02,\n",
       "                      -2.2802e-02, -6.3588e-03,  3.5946e-02, -1.8580e-02,  1.8553e-02,\n",
       "                       1.3691e-03,  3.3293e-02,  1.0821e-02, -1.0577e-02, -3.1498e-03,\n",
       "                      -1.4162e-02, -4.9431e-04,  5.2355e-03,  2.2729e-02, -1.2883e-02,\n",
       "                       5.9154e-02,  1.1512e-02, -7.2364e-03,  4.1261e-02, -2.6351e-03,\n",
       "                      -3.3032e-03,  3.3423e-02, -1.7533e-02, -1.6128e-02, -5.7894e-03,\n",
       "                      -1.4025e-02,  2.8735e-02, -2.5581e-02,  1.1237e-02, -3.9039e-02,\n",
       "                      -3.7581e-02, -1.1970e-02, -1.2555e-02,  1.9434e-02, -2.8948e-03,\n",
       "                      -2.3720e-02,  2.3603e-03, -2.1667e-02,  7.3620e-03,  6.9243e-03,\n",
       "                      -2.9235e-02, -6.6256e-03,  5.0314e-03, -4.4027e-02, -1.1383e-02,\n",
       "                      -8.4184e-03,  5.0313e-03, -2.0207e-02, -4.1501e-03,  2.3522e-02,\n",
       "                       8.4851e-03, -2.2156e-03, -2.1147e-03,  5.7881e-02, -1.9192e-02,\n",
       "                      -1.7235e-02, -1.0253e-03,  1.4571e-02, -3.1924e-02,  1.9331e-02,\n",
       "                       2.0114e-02, -8.6965e-03,  3.2256e-02,  4.3058e-03,  5.4712e-02,\n",
       "                       1.9615e-02,  1.8704e-03,  5.2401e-02, -3.4430e-02, -8.1612e-05,\n",
       "                       5.9762e-04,  2.5525e-02, -1.6064e-02, -2.2107e-04,  5.0914e-03,\n",
       "                       1.0815e-02, -1.0005e-02, -1.7143e-02, -1.5681e-02,  8.5298e-03,\n",
       "                      -3.6848e-02,  2.3611e-03,  9.8262e-03,  2.9744e-02,  1.9323e-02,\n",
       "                      -1.6335e-02,  3.2883e-03, -1.7270e-02,  2.2763e-02,  9.8032e-03,\n",
       "                      -1.2764e-02,  4.0871e-02, -9.9673e-03, -8.9770e-03,  2.0862e-02,\n",
       "                       3.0616e-03, -1.7059e-02,  3.8725e-03, -4.2900e-02,  3.4070e-02,\n",
       "                       2.7956e-02,  1.5438e-02,  1.4472e-02, -8.1820e-03, -1.1573e-02,\n",
       "                       1.9302e-02,  3.4712e-02, -2.1957e-02,  3.6883e-02,  8.5630e-03,\n",
       "                      -2.2851e-02,  6.6175e-04,  9.5112e-04,  1.5366e-02,  7.0738e-03,\n",
       "                       1.7809e-02, -1.1229e-02, -4.7060e-04, -1.4683e-02,  8.8176e-03,\n",
       "                      -5.0882e-03, -3.6376e-03,  3.1334e-02,  2.2544e-02,  9.8405e-04,\n",
       "                      -2.3720e-03, -1.2918e-02,  1.5443e-02,  8.2233e-03,  7.1529e-03,\n",
       "                       3.2825e-02, -2.0104e-03, -1.7655e-02, -1.4801e-02,  5.4752e-03,\n",
       "                       4.5423e-03, -1.3051e-02, -3.9650e-02, -2.9016e-02, -8.5384e-03,\n",
       "                      -2.8884e-02, -3.0124e-02,  6.3246e-03, -1.5233e-02, -3.7544e-03,\n",
       "                      -1.7659e-02,  1.9056e-02, -1.4498e-03,  1.3431e-02, -1.0964e-02,\n",
       "                       4.5452e-02,  1.2764e-02, -2.1018e-02,  3.3983e-02, -3.1912e-02,\n",
       "                       3.3260e-02, -1.0320e-02,  1.0350e-02, -1.9775e-02, -4.2863e-02,\n",
       "                      -5.0495e-03,  9.6319e-03, -7.5421e-03,  1.2882e-02,  4.0134e-03,\n",
       "                       6.3385e-03, -3.0139e-03,  8.3679e-03,  4.1635e-03, -6.2613e-03,\n",
       "                       2.6277e-02, -1.4394e-02, -1.3608e-02, -7.6196e-03,  9.5283e-03,\n",
       "                       1.7422e-03,  2.5673e-03, -2.9025e-03,  2.9847e-03,  2.5024e-03,\n",
       "                       2.5046e-02, -2.5419e-03, -7.8934e-04, -2.0001e-02,  2.9911e-02,\n",
       "                      -1.8285e-02,  7.0310e-03, -1.1704e-03, -1.3317e-02,  1.7797e-02,\n",
       "                      -1.4191e-02,  1.4188e-02,  1.0172e-02,  1.6443e-02, -4.8110e-03,\n",
       "                      -1.3569e-02, -1.8782e-02,  1.6926e-02,  2.8619e-03, -3.7016e-03,\n",
       "                      -2.4370e-02])),\n",
       "             ('mlp_extractor.value_net.0.weight',\n",
       "              tensor([[ 0.0258, -0.0781,  0.1049,  ...,  0.0501, -0.0005, -0.0208],\n",
       "                      [ 0.1494,  0.0542,  0.0675,  ...,  0.0640,  0.0272,  0.0994],\n",
       "                      [-0.0923, -0.0055,  0.1079,  ...,  0.0536, -0.0654,  0.0674],\n",
       "                      ...,\n",
       "                      [ 0.0520, -0.0476,  0.0897,  ...,  0.0859,  0.0255,  0.0612],\n",
       "                      [-0.0903,  0.1567,  0.1841,  ..., -0.1402, -0.2208, -0.0551],\n",
       "                      [ 0.0460,  0.0967, -0.1723,  ..., -0.0152, -0.0825,  0.1534]])),\n",
       "             ('mlp_extractor.value_net.0.bias',\n",
       "              tensor([ 0.0073, -0.0171,  0.0155, -0.0193, -0.0133, -0.0160, -0.0482, -0.0190,\n",
       "                      -0.0075,  0.0030, -0.0123, -0.0150, -0.0414,  0.0151, -0.0232, -0.0071,\n",
       "                       0.0317, -0.0380,  0.0064, -0.0079, -0.0125,  0.0227,  0.0055,  0.0281,\n",
       "                      -0.0529,  0.0325,  0.0030, -0.0118,  0.0103, -0.0017,  0.0199, -0.0090,\n",
       "                      -0.0195, -0.0411,  0.0095,  0.0086,  0.0282, -0.0010,  0.0117,  0.0123,\n",
       "                       0.0093,  0.0220, -0.0035, -0.0292,  0.0189, -0.0098, -0.0344,  0.0114,\n",
       "                      -0.0050, -0.0643, -0.0059,  0.0310,  0.0136, -0.0199,  0.0402,  0.0118,\n",
       "                      -0.0216,  0.0063,  0.0250, -0.0296,  0.0183, -0.0258, -0.0150,  0.0188,\n",
       "                       0.0134,  0.0280,  0.0019,  0.0076, -0.0032,  0.0001,  0.0159,  0.0034,\n",
       "                      -0.0075, -0.0161,  0.0066,  0.0083, -0.0256, -0.0052, -0.0293,  0.0066,\n",
       "                       0.0029,  0.0149,  0.0256,  0.0195, -0.0138, -0.0393, -0.0222, -0.0050,\n",
       "                       0.0161,  0.0128,  0.0078, -0.0042, -0.0154, -0.0137, -0.0071, -0.0200,\n",
       "                      -0.0319,  0.0311, -0.0018, -0.0017, -0.0239, -0.0181,  0.0355,  0.0221,\n",
       "                      -0.0281, -0.0100, -0.0033, -0.0069,  0.0126, -0.0165,  0.0251,  0.0010,\n",
       "                       0.0250,  0.0176, -0.0393, -0.0370, -0.0079,  0.0139, -0.0199, -0.0082,\n",
       "                       0.0288,  0.0476,  0.0187,  0.0241,  0.0296, -0.0201, -0.0502, -0.0255,\n",
       "                       0.0019,  0.0212, -0.0188, -0.0122, -0.0228,  0.0101, -0.0274, -0.0159,\n",
       "                       0.0330, -0.0052,  0.0089,  0.0152, -0.0158,  0.0064, -0.0217,  0.0302,\n",
       "                       0.0088,  0.0203,  0.0293,  0.0118, -0.0266, -0.0313,  0.0287,  0.0292,\n",
       "                       0.0227,  0.0242,  0.0089, -0.0319,  0.0309,  0.0305,  0.0053,  0.0116,\n",
       "                       0.0179, -0.0401,  0.0046,  0.0064, -0.0346,  0.0299, -0.0042, -0.0296,\n",
       "                       0.0248,  0.0164,  0.0080,  0.0439, -0.0256, -0.0213,  0.0053,  0.0067,\n",
       "                       0.0025, -0.0117, -0.0139, -0.0202,  0.0104, -0.0056,  0.0295,  0.0389,\n",
       "                       0.0347, -0.0263,  0.0114, -0.0407,  0.0029,  0.0330, -0.0109,  0.0093,\n",
       "                       0.0185, -0.0436, -0.0021,  0.0105,  0.0289,  0.0050,  0.0291, -0.0307,\n",
       "                      -0.0111,  0.0218,  0.0322, -0.0216, -0.0034,  0.0108,  0.0139,  0.0242,\n",
       "                      -0.0039, -0.0260,  0.0204, -0.0051, -0.0184, -0.0102, -0.0113, -0.0258,\n",
       "                      -0.0226,  0.0083,  0.0291,  0.0410, -0.0232, -0.0176, -0.0105, -0.0313,\n",
       "                       0.0339,  0.0156, -0.0041,  0.0539, -0.0181, -0.0149,  0.0247,  0.0223,\n",
       "                       0.0065, -0.0142,  0.0087,  0.0416, -0.0010, -0.0007, -0.0284,  0.0091,\n",
       "                      -0.0299, -0.0273, -0.0013,  0.0311,  0.0177,  0.0006, -0.0274,  0.0434,\n",
       "                       0.0060,  0.0048, -0.0065,  0.0375,  0.0143, -0.0056,  0.0025,  0.0400])),\n",
       "             ('mlp_extractor.value_net.2.weight',\n",
       "              tensor([[ 0.1031, -0.0784,  0.1225,  ...,  0.0166, -0.0647,  0.0448],\n",
       "                      [-0.0746, -0.2045,  0.0213,  ...,  0.0200,  0.0301,  0.0594],\n",
       "                      [-0.0485,  0.1501, -0.0747,  ..., -0.0354, -0.0677,  0.0100],\n",
       "                      ...,\n",
       "                      [ 0.3010, -0.0592, -0.0250,  ..., -0.1353, -0.0817, -0.0257],\n",
       "                      [ 0.0583, -0.0296, -0.0965,  ...,  0.1907,  0.0751, -0.0286],\n",
       "                      [-0.0687,  0.1230,  0.0270,  ...,  0.0339,  0.0858, -0.0454]])),\n",
       "             ('mlp_extractor.value_net.2.bias',\n",
       "              tensor([ 3.5799e-03,  3.5292e-03, -1.9715e-02, -1.0328e-02,  1.7350e-02,\n",
       "                      -1.7284e-02,  9.3694e-04, -1.8285e-02, -6.7587e-03,  3.6638e-03,\n",
       "                      -1.4437e-02,  1.9942e-02, -2.1250e-02, -2.2902e-02,  2.3250e-02,\n",
       "                      -9.0199e-03, -2.0914e-02,  1.6462e-02,  1.6864e-02,  1.6971e-02,\n",
       "                       1.0805e-02,  9.4597e-03,  6.0784e-04, -3.4437e-03, -1.5691e-02,\n",
       "                       1.0027e-03,  1.3647e-02, -5.8386e-03, -1.6246e-02,  1.9832e-02,\n",
       "                       1.8696e-02, -1.8948e-02, -6.1973e-03,  1.1848e-02,  1.3520e-02,\n",
       "                      -5.1360e-03, -1.0215e-02,  1.6143e-02,  1.0493e-02,  9.4610e-03,\n",
       "                      -2.1828e-02,  1.2389e-02, -2.3929e-02, -1.5668e-02, -5.4613e-04,\n",
       "                       9.8429e-03, -4.7456e-03,  1.1693e-02,  1.6548e-02, -2.3037e-02,\n",
       "                       6.6384e-04, -2.4440e-03,  1.8023e-02, -1.5377e-02,  2.9876e-03,\n",
       "                       1.4220e-02, -6.3246e-03,  6.4127e-03,  2.1948e-02,  1.6072e-02,\n",
       "                      -3.6497e-03,  7.4768e-03,  1.9767e-02, -1.7684e-02, -5.7277e-03,\n",
       "                      -5.6413e-03, -1.7375e-02,  1.5375e-02,  1.7958e-02, -1.6137e-02,\n",
       "                      -1.2186e-02,  1.5668e-05,  2.5710e-03, -6.8798e-03, -1.8157e-02,\n",
       "                      -1.4367e-02, -6.2862e-03, -1.1924e-02, -1.5660e-02,  1.9036e-02,\n",
       "                      -2.3311e-02,  9.5750e-03, -1.9810e-02,  2.0722e-02,  6.2475e-04,\n",
       "                      -1.5477e-02,  1.1501e-02, -1.0731e-02,  2.7525e-03, -8.3308e-03,\n",
       "                      -2.5942e-02, -1.4650e-03, -8.8326e-03,  2.0180e-03, -7.1282e-03,\n",
       "                       4.4672e-03,  4.1499e-03,  1.4123e-02, -3.6176e-03,  1.8223e-02,\n",
       "                       2.1647e-03,  6.9139e-03,  1.0047e-03, -4.0867e-03,  1.2341e-02,\n",
       "                      -7.2736e-03,  2.3376e-02,  1.7278e-02,  6.8736e-04, -1.8320e-02,\n",
       "                       1.3428e-02, -1.5306e-02,  2.0008e-02,  1.6215e-06,  1.6775e-02,\n",
       "                      -1.5133e-02, -1.3126e-02, -1.2041e-02,  1.5071e-02, -1.9596e-02,\n",
       "                      -2.3280e-02,  1.5094e-02, -2.1058e-02,  2.0434e-02, -1.8828e-03,\n",
       "                      -5.4423e-03, -2.1646e-02,  5.7857e-03,  2.1414e-02,  1.6875e-03,\n",
       "                       2.2360e-02, -2.1373e-02, -9.8489e-03,  1.6259e-02,  1.7101e-02,\n",
       "                      -2.2432e-02,  1.9357e-02, -1.9886e-02, -2.0919e-02, -1.9031e-02,\n",
       "                      -1.6509e-03, -1.6547e-03,  1.5982e-02,  5.1847e-03,  1.9170e-02,\n",
       "                       1.7896e-02,  2.4410e-03,  1.1951e-02, -2.4551e-02,  1.6849e-02,\n",
       "                      -1.9074e-02, -2.2394e-02, -2.1093e-02,  2.0049e-02, -1.7392e-02,\n",
       "                       2.3051e-02, -1.7531e-02,  4.6713e-04, -3.2929e-03,  3.0393e-03,\n",
       "                       1.0845e-02, -2.2677e-02, -1.7766e-02, -5.2143e-03, -1.9969e-02,\n",
       "                      -2.1128e-02, -1.7207e-02,  3.5592e-03,  3.8090e-03,  1.3139e-02,\n",
       "                      -2.2284e-02,  1.3133e-02, -1.9177e-03, -1.9009e-02, -2.1424e-02,\n",
       "                       1.5563e-03,  1.4668e-02, -2.0922e-02, -2.2657e-03,  2.2310e-02,\n",
       "                      -1.1378e-02, -2.0817e-02,  6.2105e-04,  1.2367e-02, -4.5331e-03,\n",
       "                       1.0558e-02,  5.1795e-03, -2.2744e-02,  1.8500e-02, -2.2728e-02,\n",
       "                      -1.8266e-02,  4.4167e-03,  2.2934e-02, -1.0485e-02, -1.5243e-02,\n",
       "                      -3.7956e-03, -1.3557e-02, -1.7258e-02,  2.4479e-02, -2.1338e-02,\n",
       "                      -1.9147e-02,  2.0108e-02,  6.1759e-03,  8.7468e-03, -3.2058e-03,\n",
       "                       1.2333e-02, -2.0609e-02, -3.1282e-03, -2.4115e-03, -1.0368e-02,\n",
       "                      -1.8686e-02, -9.9143e-03, -1.2893e-02, -7.8900e-03, -1.9347e-02,\n",
       "                       2.9915e-03,  1.7967e-02, -1.4676e-02,  2.0105e-02, -5.5169e-03,\n",
       "                       1.9404e-02,  2.3219e-02,  1.8098e-02, -5.3687e-03, -5.9559e-03,\n",
       "                      -4.4813e-03, -1.5034e-03, -1.3383e-02,  1.9927e-02, -3.6679e-03,\n",
       "                       1.7204e-02, -5.4026e-03,  1.2775e-02,  2.2480e-03, -4.0149e-03,\n",
       "                      -4.6519e-03,  2.7157e-02,  2.2412e-03, -2.5997e-03, -2.6912e-02,\n",
       "                       2.0699e-02, -1.8649e-02,  5.4057e-04,  2.2096e-02, -6.5883e-04,\n",
       "                      -8.6348e-05,  2.0106e-02,  1.8275e-02, -1.8689e-02,  3.5094e-03,\n",
       "                       1.7725e-02,  7.9392e-03, -1.5728e-03,  1.8433e-02,  5.5552e-03,\n",
       "                      -6.0163e-03])),\n",
       "             ('action_net.weight',\n",
       "              tensor([[ 0.0012,  0.0227, -0.0473,  ..., -0.0274, -0.0431,  0.0210],\n",
       "                      [ 0.0113,  0.0733, -0.0241,  ..., -0.0195,  0.0170, -0.0060],\n",
       "                      [ 0.0015, -0.0290,  0.0109,  ..., -0.0131,  0.0136,  0.0368],\n",
       "                      ...,\n",
       "                      [-0.0149,  0.0221,  0.0098,  ...,  0.0015, -0.0339,  0.0399],\n",
       "                      [ 0.0411, -0.0210,  0.0034,  ...,  0.0035, -0.0071,  0.0404],\n",
       "                      [ 0.0169, -0.0078,  0.0210,  ..., -0.0110, -0.0452, -0.0073]])),\n",
       "             ('action_net.bias',\n",
       "              tensor([ 7.1976e-03, -5.1840e-05, -1.8893e-02, -1.4768e-02, -2.1590e-02,\n",
       "                      -5.3293e-04, -2.1903e-02, -3.6274e-02, -6.4636e-03,  2.2269e-02,\n",
       "                      -1.0875e-02,  3.7804e-02, -1.9634e-02, -3.0975e-03,  7.7602e-03,\n",
       "                       2.1053e-02, -1.2791e-02,  4.7547e-02, -5.0211e-04,  3.2260e-02,\n",
       "                       2.1611e-02,  4.7714e-02,  4.0008e-02, -3.6381e-03, -1.5408e-02,\n",
       "                       2.9937e-02,  1.1037e-02, -1.4739e-02, -3.4997e-02,  3.0742e-02,\n",
       "                       1.1662e-02,  4.3333e-03, -4.1599e-04, -2.0226e-02,  3.1167e-02,\n",
       "                       4.4749e-03, -1.5468e-02,  1.3803e-02,  3.2176e-02,  1.3382e-02,\n",
       "                      -1.9587e-02,  4.2042e-03,  2.7800e-03,  3.3353e-02,  2.5322e-02,\n",
       "                       3.6295e-02, -2.6026e-03, -1.0599e-02, -2.5099e-02,  1.8091e-02,\n",
       "                       6.1407e-02,  1.6070e-02,  5.6761e-02,  4.9916e-03,  2.9991e-02,\n",
       "                      -1.8809e-02, -1.3155e-03,  1.8749e-03, -1.5828e-02, -5.5678e-03,\n",
       "                      -2.2151e-02, -1.0909e-02, -5.0003e-02, -1.3498e-02])),\n",
       "             ('value_net.weight',\n",
       "              tensor([[-3.3037e-03,  5.3284e-03, -9.3936e-02,  9.3759e-02, -7.8912e-02,\n",
       "                        1.7651e-02, -3.1864e-03,  1.4838e-02,  3.6118e-02, -2.1965e-03,\n",
       "                       -1.8197e-02, -1.1277e-01,  3.9909e-02,  1.2386e-01,  7.8707e-02,\n",
       "                        4.8020e-02, -5.5264e-02,  2.9150e-02,  1.2501e-01,  7.0784e-02,\n",
       "                        1.1205e-01,  5.6027e-03, -5.6052e-03, -1.5464e-03, -2.6084e-02,\n",
       "                        1.8369e-02,  6.4251e-02,  5.6639e-03, -8.8315e-03, -4.6602e-02,\n",
       "                       -5.5952e-02,  1.3690e-01,  2.1227e-02,  5.3258e-02, -9.6172e-03,\n",
       "                        4.0385e-04, -1.2305e-03, -1.4693e-01,  1.1193e-01, -1.1170e-03,\n",
       "                        3.9019e-02, -2.3649e-02,  9.3961e-02, -9.2013e-02,  4.6556e-03,\n",
       "                        2.4766e-02, -1.1856e-02, -4.0379e-02, -9.1541e-03, -4.7995e-02,\n",
       "                        1.2343e-03, -1.1859e-03, -9.0648e-02, -1.1912e-01, -3.0946e-03,\n",
       "                       -4.7574e-02,  1.3759e-02, -3.0798e-03, -8.3888e-02,  3.3826e-02,\n",
       "                        2.1512e-03,  3.5112e-03, -3.0947e-02, -3.9469e-02,  1.4467e-03,\n",
       "                        5.8429e-03, -4.3625e-02, -9.0233e-03,  6.3658e-02,  1.1783e-01,\n",
       "                       -8.9585e-02, -3.9797e-03,  2.1342e-03,  1.6873e-03, -4.2570e-02,\n",
       "                        1.7917e-02, -4.5486e-04, -6.3664e-02,  3.0962e-02,  7.5418e-02,\n",
       "                       -8.5835e-02, -3.8027e-03, -5.4829e-02, -8.5183e-02,  4.9747e-03,\n",
       "                       -1.7616e-02,  3.7681e-02, -8.1497e-03, -3.2110e-02, -4.7939e-03,\n",
       "                        5.9446e-02,  1.2871e-04, -1.1236e-03,  1.0122e-04,  5.9017e-03,\n",
       "                        3.4359e-03, -2.4740e-03, -9.4853e-02, -2.3892e-03, -8.1743e-02,\n",
       "                       -1.4456e-04, -1.7734e-03,  5.2059e-03, -2.7922e-03, -1.3474e-02,\n",
       "                        3.6450e-02,  7.0219e-02,  6.5782e-02, -1.7412e-03,  4.3386e-02,\n",
       "                       -3.6895e-03, -4.2182e-02, -5.8059e-02, -2.2665e-03, -5.7482e-02,\n",
       "                       -9.4000e-03,  3.1009e-02, -6.0081e-02,  2.9139e-02,  1.0468e-01,\n",
       "                        1.1024e-01,  8.5318e-02, -6.7113e-02, -1.1693e-01,  2.0401e-03,\n",
       "                        9.4724e-03,  4.8819e-02,  7.7481e-03,  7.7007e-02, -2.4200e-03,\n",
       "                        8.8408e-02, -5.8496e-02, -5.1439e-04,  9.0237e-02,  3.7648e-02,\n",
       "                        6.7163e-02, -6.7338e-02,  1.0306e-01,  5.6972e-02,  6.1626e-02,\n",
       "                        5.8335e-03,  4.4375e-03, -7.0211e-02,  2.6161e-03,  5.2987e-02,\n",
       "                       -6.7511e-02, -2.0358e-02,  1.0349e-01,  5.6568e-02,  2.9279e-02,\n",
       "                       -7.6973e-02,  5.6301e-02,  3.8001e-02, -7.7740e-02,  2.8528e-02,\n",
       "                        5.9497e-02, -5.6108e-02, -2.2918e-03,  6.8027e-04, -4.1869e-03,\n",
       "                        1.2244e-03,  5.1292e-02,  3.3933e-02,  1.4602e-03, -4.8650e-02,\n",
       "                        1.5021e-01,  2.3874e-02,  9.1171e-04,  5.1501e-04,  3.2667e-02,\n",
       "                        6.0254e-02,  4.0823e-02,  6.8889e-04, -5.0441e-02,  2.6259e-02,\n",
       "                       -2.2578e-03, -1.6464e-01, -4.4331e-02,  1.3884e-03, -8.8885e-02,\n",
       "                       -6.9349e-02,  1.5955e-01,  5.2212e-03,  3.4174e-02, -1.0216e-02,\n",
       "                       -4.7145e-02, -5.4640e-03,  4.1004e-02,  1.3680e-01,  3.7153e-02,\n",
       "                        1.3271e-01, -1.7563e-02, -7.9908e-02, -5.3408e-03,  6.6469e-02,\n",
       "                       -3.7583e-03, -7.7805e-02, -3.3602e-02, -8.1072e-02,  8.2813e-02,\n",
       "                       -5.8939e-02,  2.5783e-02,  5.9611e-03,  5.1634e-02, -1.8126e-03,\n",
       "                       -2.9491e-02,  6.7121e-02, -3.0367e-03, -3.8643e-03, -9.6008e-02,\n",
       "                       -1.0055e-01,  9.4307e-03,  2.6973e-02, -7.6093e-03, -3.8869e-02,\n",
       "                       -1.6433e-03, -5.9397e-02, -7.7529e-02,  5.9596e-02, -8.4991e-03,\n",
       "                        4.8007e-02, -5.4996e-02, -6.5658e-02,  1.5903e-04, -9.2767e-02,\n",
       "                        7.7916e-03,  1.5767e-04, -5.0047e-02, -3.0773e-02, -8.7600e-02,\n",
       "                        8.4599e-02,  1.3865e-03,  9.1907e-03, -1.3307e-04, -4.5890e-03,\n",
       "                        1.2302e-03, -6.6371e-02,  2.2931e-03, -3.8944e-03,  1.7272e-02,\n",
       "                       -2.2133e-02, -5.1664e-02,  5.3131e-04, -1.9438e-02,  3.2887e-02,\n",
       "                       -1.1220e-02, -4.9104e-02,  3.0505e-02,  2.3949e-02, -6.2865e-04,\n",
       "                        7.8438e-02, -3.3102e-04, -1.7982e-03, -3.1845e-02,  3.5578e-02,\n",
       "                        1.4502e-03]])),\n",
       "             ('value_net.bias', tensor([0.0009]))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92687fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]], device='cuda:0')),\n",
       "             ('features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]], device='cuda:0')),\n",
       "             ('features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]], device='cuda:0')),\n",
       "             ('features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03], device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.0.weight',\n",
       "              tensor([[ 0.0052, -0.0291, -0.1622,  ..., -0.0602,  0.0157, -0.1659],\n",
       "                      [ 0.2019, -0.0419, -0.0568,  ..., -0.0626,  0.1577,  0.0271],\n",
       "                      [-0.0572,  0.1457,  0.0097,  ..., -0.0697,  0.0149,  0.1527],\n",
       "                      ...,\n",
       "                      [ 0.1710, -0.0119, -0.0412,  ..., -0.0447, -0.0182, -0.2364],\n",
       "                      [ 0.0447,  0.1429,  0.0491,  ...,  0.0427, -0.1254, -0.0774],\n",
       "                      [ 0.0038, -0.0645,  0.0989,  ...,  0.0437,  0.0210,  0.1546]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.0.bias',\n",
       "              tensor([-3.7934e-02, -1.0120e-02, -1.7950e-02,  1.3979e-02, -8.9758e-03,\n",
       "                       9.3981e-03,  1.4142e-02, -1.4561e-02,  7.6285e-03, -7.7994e-04,\n",
       "                       3.3254e-02,  3.0155e-03, -5.0676e-03, -8.6990e-03, -6.2035e-03,\n",
       "                      -1.2432e-02,  2.6509e-02,  2.8312e-02, -1.0761e-02, -6.4396e-03,\n",
       "                      -2.3653e-02, -5.9161e-03, -1.6559e-03,  2.3093e-03,  2.1843e-02,\n",
       "                      -5.1557e-03,  3.7100e-02,  2.4642e-02, -2.5497e-02,  2.5407e-02,\n",
       "                       3.0578e-02,  2.9345e-02,  7.7088e-03, -1.1796e-02, -1.3831e-02,\n",
       "                      -2.3595e-02, -1.1430e-03, -1.2029e-02, -7.1556e-03,  1.3530e-02,\n",
       "                      -2.2087e-02, -5.5528e-03,  4.2695e-03,  2.3459e-04, -3.0454e-05,\n",
       "                      -2.4168e-02,  7.0001e-03, -2.1349e-02,  8.1098e-03,  2.3649e-04,\n",
       "                      -1.2144e-02, -1.6706e-02, -1.0958e-02, -2.8586e-03,  3.7588e-02,\n",
       "                      -8.2629e-03,  4.8411e-03, -8.2878e-03,  1.0644e-02,  5.4867e-03,\n",
       "                       6.1514e-03,  9.5967e-03,  1.0890e-02,  4.9025e-03,  1.5948e-02,\n",
       "                       2.1311e-02,  9.8605e-03, -6.4243e-03, -2.9398e-03, -3.6904e-03,\n",
       "                      -9.9446e-03,  1.9047e-02,  1.4092e-02,  2.4026e-03,  3.2092e-02,\n",
       "                      -1.5059e-02,  8.1860e-03,  2.6424e-02, -3.0271e-02,  3.8252e-02,\n",
       "                       1.3251e-02, -1.6951e-02,  5.3191e-03,  2.9410e-02, -2.0283e-02,\n",
       "                       2.5827e-02, -4.1000e-03, -1.0457e-02,  2.1510e-03,  1.4410e-02,\n",
       "                      -4.7814e-03,  3.4634e-03,  4.0821e-03,  2.1709e-02,  3.6088e-02,\n",
       "                       8.9005e-03,  1.4891e-02,  6.9741e-04, -1.8474e-02,  7.3035e-03,\n",
       "                       1.6245e-02, -3.5832e-02,  8.3168e-03, -1.0705e-02,  2.0325e-02,\n",
       "                       2.9341e-02, -3.1170e-02,  1.2995e-02,  1.0005e-02, -3.5040e-02,\n",
       "                       1.2313e-02, -1.4531e-02,  2.3488e-02,  8.1426e-03, -1.0364e-02,\n",
       "                       2.7742e-03, -3.1425e-02,  1.2838e-04, -1.4976e-02, -4.1408e-03,\n",
       "                       8.6572e-03,  1.7360e-02,  3.3624e-02,  1.0835e-02, -1.7576e-02,\n",
       "                      -1.2138e-02,  1.5603e-02, -1.0795e-02,  2.0145e-02, -2.9814e-03,\n",
       "                       1.9765e-03, -8.7999e-03, -6.0783e-03,  1.3500e-02, -3.3708e-02,\n",
       "                      -1.0044e-02,  1.5282e-02,  1.2506e-02,  1.2176e-02,  7.7159e-03,\n",
       "                       3.4869e-02,  1.3253e-02,  5.5851e-05,  1.8154e-03, -6.9276e-04,\n",
       "                      -1.5390e-02,  2.1272e-02,  1.5382e-02, -1.2867e-03, -1.2366e-02,\n",
       "                      -2.6879e-02, -2.3791e-04, -1.2761e-02, -1.2157e-02, -1.4863e-02,\n",
       "                       4.1211e-02, -3.5103e-03,  1.8319e-02, -4.5932e-03, -5.1984e-03,\n",
       "                       2.5223e-02,  6.9816e-03, -8.6695e-03,  1.1261e-02, -1.7240e-03,\n",
       "                      -6.5262e-04, -8.2426e-03, -3.1230e-03, -3.0566e-02,  2.8768e-02,\n",
       "                       1.2229e-02,  8.3468e-03,  2.0897e-03,  1.0116e-02,  1.9699e-03,\n",
       "                       2.2369e-03, -1.7555e-02, -4.4118e-02,  2.1739e-02, -4.9466e-02,\n",
       "                      -8.6298e-03, -4.1051e-02,  2.9664e-02,  1.9345e-02, -2.0059e-02,\n",
       "                       2.3699e-02, -3.7010e-02,  2.4064e-02, -3.7450e-03,  4.3794e-02,\n",
       "                       3.8838e-02,  8.5117e-03, -7.4019e-03,  2.0133e-02,  2.1669e-02,\n",
       "                      -1.1451e-02,  1.6833e-02, -1.3509e-02, -7.1325e-04,  1.1084e-02,\n",
       "                       2.7922e-02,  1.0219e-02, -7.6056e-05, -1.0354e-02, -2.5249e-02,\n",
       "                       1.2617e-02, -2.6633e-03,  3.5738e-03,  3.5735e-04,  1.8399e-02,\n",
       "                      -4.8047e-03,  4.1018e-03,  4.1222e-03,  1.7260e-02, -1.0157e-02,\n",
       "                      -1.2880e-02, -2.6215e-02, -2.7168e-02,  1.0103e-02,  1.7706e-02,\n",
       "                      -4.7546e-02,  9.3363e-03, -2.8084e-02, -1.0535e-02, -1.5182e-02,\n",
       "                      -1.3819e-02, -1.1448e-02, -6.4746e-03,  7.6021e-04,  1.2651e-02,\n",
       "                      -1.0050e-02,  2.2821e-02,  1.5586e-02, -2.1990e-02, -9.9179e-03,\n",
       "                      -1.3580e-02,  1.8374e-03, -1.4163e-02, -5.2409e-03, -1.2622e-02,\n",
       "                      -7.0958e-04,  2.5395e-02, -1.7106e-02,  1.8910e-02,  4.9914e-06,\n",
       "                       3.1792e-03, -1.6064e-02,  6.5150e-03, -1.2743e-03,  1.4860e-03,\n",
       "                       7.6464e-03, -1.0430e-02, -7.9494e-03,  7.8145e-04,  4.2292e-03,\n",
       "                      -1.3421e-02], device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.2.weight',\n",
       "              tensor([[ 0.0511,  0.0201, -0.1065,  ...,  0.1073, -0.1929,  0.0241],\n",
       "                      [-0.0182, -0.0378,  0.0256,  ...,  0.0010, -0.0474,  0.1143],\n",
       "                      [-0.1059, -0.0264,  0.0380,  ...,  0.0188,  0.0859, -0.0179],\n",
       "                      ...,\n",
       "                      [ 0.0793, -0.0118, -0.1422,  ...,  0.1023,  0.1145, -0.0365],\n",
       "                      [-0.2033,  0.0724, -0.0057,  ...,  0.1733,  0.0949,  0.0662],\n",
       "                      [-0.1075, -0.1196,  0.0106,  ..., -0.0087, -0.0097,  0.0297]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.2.bias',\n",
       "              tensor([ 5.8172e-03, -9.2728e-03, -1.5235e-02,  2.1914e-02, -1.1689e-02,\n",
       "                      -3.3092e-03,  3.9647e-03,  3.0486e-02, -1.0433e-03, -2.3171e-02,\n",
       "                      -3.3122e-02,  7.0034e-03,  2.3954e-02,  8.0406e-03,  2.2886e-02,\n",
       "                       4.0525e-02, -3.2603e-02,  1.2374e-02,  1.5371e-02,  1.8317e-02,\n",
       "                      -3.2269e-02,  3.0887e-03,  9.6856e-04, -4.9347e-03, -8.1643e-03,\n",
       "                      -6.9902e-03, -2.0729e-02, -1.7335e-02,  1.0368e-02,  4.6599e-02,\n",
       "                      -9.1468e-03,  6.8571e-03, -3.8949e-02, -2.3278e-02,  2.9535e-02,\n",
       "                       2.7574e-02, -2.5148e-02, -4.7471e-03, -3.7972e-03,  3.3504e-02,\n",
       "                       1.0143e-03,  1.5877e-02,  4.4178e-03, -3.8147e-04,  5.7864e-03,\n",
       "                       8.3002e-03, -4.5355e-03, -1.7833e-03,  5.7902e-03, -3.3542e-02,\n",
       "                      -4.1374e-02, -4.3449e-03,  2.2690e-02,  4.9732e-02, -3.6212e-02,\n",
       "                      -2.2802e-02, -6.3588e-03,  3.5946e-02, -1.8580e-02,  1.8553e-02,\n",
       "                       1.3691e-03,  3.3293e-02,  1.0821e-02, -1.0577e-02, -3.1498e-03,\n",
       "                      -1.4162e-02, -4.9431e-04,  5.2355e-03,  2.2729e-02, -1.2883e-02,\n",
       "                       5.9154e-02,  1.1512e-02, -7.2364e-03,  4.1261e-02, -2.6351e-03,\n",
       "                      -3.3032e-03,  3.3423e-02, -1.7533e-02, -1.6128e-02, -5.7894e-03,\n",
       "                      -1.4025e-02,  2.8735e-02, -2.5581e-02,  1.1237e-02, -3.9039e-02,\n",
       "                      -3.7581e-02, -1.1970e-02, -1.2555e-02,  1.9434e-02, -2.8948e-03,\n",
       "                      -2.3720e-02,  2.3603e-03, -2.1667e-02,  7.3620e-03,  6.9243e-03,\n",
       "                      -2.9235e-02, -6.6256e-03,  5.0314e-03, -4.4027e-02, -1.1383e-02,\n",
       "                      -8.4184e-03,  5.0313e-03, -2.0207e-02, -4.1501e-03,  2.3522e-02,\n",
       "                       8.4851e-03, -2.2156e-03, -2.1147e-03,  5.7881e-02, -1.9192e-02,\n",
       "                      -1.7235e-02, -1.0253e-03,  1.4571e-02, -3.1924e-02,  1.9331e-02,\n",
       "                       2.0114e-02, -8.6965e-03,  3.2256e-02,  4.3058e-03,  5.4712e-02,\n",
       "                       1.9615e-02,  1.8704e-03,  5.2401e-02, -3.4430e-02, -8.1612e-05,\n",
       "                       5.9762e-04,  2.5525e-02, -1.6064e-02, -2.2107e-04,  5.0914e-03,\n",
       "                       1.0815e-02, -1.0005e-02, -1.7143e-02, -1.5681e-02,  8.5298e-03,\n",
       "                      -3.6848e-02,  2.3611e-03,  9.8262e-03,  2.9744e-02,  1.9323e-02,\n",
       "                      -1.6335e-02,  3.2883e-03, -1.7270e-02,  2.2763e-02,  9.8032e-03,\n",
       "                      -1.2764e-02,  4.0871e-02, -9.9673e-03, -8.9770e-03,  2.0862e-02,\n",
       "                       3.0616e-03, -1.7059e-02,  3.8725e-03, -4.2900e-02,  3.4070e-02,\n",
       "                       2.7956e-02,  1.5438e-02,  1.4472e-02, -8.1820e-03, -1.1573e-02,\n",
       "                       1.9302e-02,  3.4712e-02, -2.1957e-02,  3.6883e-02,  8.5630e-03,\n",
       "                      -2.2851e-02,  6.6175e-04,  9.5112e-04,  1.5366e-02,  7.0738e-03,\n",
       "                       1.7809e-02, -1.1229e-02, -4.7060e-04, -1.4683e-02,  8.8176e-03,\n",
       "                      -5.0882e-03, -3.6376e-03,  3.1334e-02,  2.2544e-02,  9.8405e-04,\n",
       "                      -2.3720e-03, -1.2918e-02,  1.5443e-02,  8.2233e-03,  7.1529e-03,\n",
       "                       3.2825e-02, -2.0104e-03, -1.7655e-02, -1.4801e-02,  5.4752e-03,\n",
       "                       4.5423e-03, -1.3051e-02, -3.9650e-02, -2.9016e-02, -8.5384e-03,\n",
       "                      -2.8884e-02, -3.0124e-02,  6.3246e-03, -1.5233e-02, -3.7544e-03,\n",
       "                      -1.7659e-02,  1.9056e-02, -1.4498e-03,  1.3431e-02, -1.0964e-02,\n",
       "                       4.5452e-02,  1.2764e-02, -2.1018e-02,  3.3983e-02, -3.1912e-02,\n",
       "                       3.3260e-02, -1.0320e-02,  1.0350e-02, -1.9775e-02, -4.2863e-02,\n",
       "                      -5.0495e-03,  9.6319e-03, -7.5421e-03,  1.2882e-02,  4.0134e-03,\n",
       "                       6.3385e-03, -3.0139e-03,  8.3679e-03,  4.1635e-03, -6.2613e-03,\n",
       "                       2.6277e-02, -1.4394e-02, -1.3608e-02, -7.6196e-03,  9.5283e-03,\n",
       "                       1.7422e-03,  2.5673e-03, -2.9025e-03,  2.9847e-03,  2.5024e-03,\n",
       "                       2.5046e-02, -2.5419e-03, -7.8934e-04, -2.0001e-02,  2.9911e-02,\n",
       "                      -1.8285e-02,  7.0310e-03, -1.1704e-03, -1.3317e-02,  1.7797e-02,\n",
       "                      -1.4191e-02,  1.4188e-02,  1.0172e-02,  1.6443e-02, -4.8110e-03,\n",
       "                      -1.3569e-02, -1.8782e-02,  1.6926e-02,  2.8619e-03, -3.7016e-03,\n",
       "                      -2.4370e-02], device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.0.weight',\n",
       "              tensor([[ 0.0258, -0.0781,  0.1049,  ...,  0.0501, -0.0005, -0.0208],\n",
       "                      [ 0.1494,  0.0542,  0.0675,  ...,  0.0640,  0.0272,  0.0994],\n",
       "                      [-0.0923, -0.0055,  0.1079,  ...,  0.0536, -0.0654,  0.0674],\n",
       "                      ...,\n",
       "                      [ 0.0520, -0.0476,  0.0897,  ...,  0.0859,  0.0255,  0.0612],\n",
       "                      [-0.0903,  0.1567,  0.1841,  ..., -0.1402, -0.2208, -0.0551],\n",
       "                      [ 0.0460,  0.0967, -0.1723,  ..., -0.0152, -0.0825,  0.1534]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.0.bias',\n",
       "              tensor([ 0.0073, -0.0171,  0.0155, -0.0193, -0.0133, -0.0160, -0.0482, -0.0190,\n",
       "                      -0.0075,  0.0030, -0.0123, -0.0150, -0.0414,  0.0151, -0.0232, -0.0071,\n",
       "                       0.0317, -0.0380,  0.0064, -0.0079, -0.0125,  0.0227,  0.0055,  0.0281,\n",
       "                      -0.0529,  0.0325,  0.0030, -0.0118,  0.0103, -0.0017,  0.0199, -0.0090,\n",
       "                      -0.0195, -0.0411,  0.0095,  0.0086,  0.0282, -0.0010,  0.0117,  0.0123,\n",
       "                       0.0093,  0.0220, -0.0035, -0.0292,  0.0189, -0.0098, -0.0344,  0.0114,\n",
       "                      -0.0050, -0.0643, -0.0059,  0.0310,  0.0136, -0.0199,  0.0402,  0.0118,\n",
       "                      -0.0216,  0.0063,  0.0250, -0.0296,  0.0183, -0.0258, -0.0150,  0.0188,\n",
       "                       0.0134,  0.0280,  0.0019,  0.0076, -0.0032,  0.0001,  0.0159,  0.0034,\n",
       "                      -0.0075, -0.0161,  0.0066,  0.0083, -0.0256, -0.0052, -0.0293,  0.0066,\n",
       "                       0.0029,  0.0149,  0.0256,  0.0195, -0.0138, -0.0393, -0.0222, -0.0050,\n",
       "                       0.0161,  0.0128,  0.0078, -0.0042, -0.0154, -0.0137, -0.0071, -0.0200,\n",
       "                      -0.0319,  0.0311, -0.0018, -0.0017, -0.0239, -0.0181,  0.0355,  0.0221,\n",
       "                      -0.0281, -0.0100, -0.0033, -0.0069,  0.0126, -0.0165,  0.0251,  0.0010,\n",
       "                       0.0250,  0.0176, -0.0393, -0.0370, -0.0079,  0.0139, -0.0199, -0.0082,\n",
       "                       0.0288,  0.0476,  0.0187,  0.0241,  0.0296, -0.0201, -0.0502, -0.0255,\n",
       "                       0.0019,  0.0212, -0.0188, -0.0122, -0.0228,  0.0101, -0.0274, -0.0159,\n",
       "                       0.0330, -0.0052,  0.0089,  0.0152, -0.0158,  0.0064, -0.0217,  0.0302,\n",
       "                       0.0088,  0.0203,  0.0293,  0.0118, -0.0266, -0.0313,  0.0287,  0.0292,\n",
       "                       0.0227,  0.0242,  0.0089, -0.0319,  0.0309,  0.0305,  0.0053,  0.0116,\n",
       "                       0.0179, -0.0401,  0.0046,  0.0064, -0.0346,  0.0299, -0.0042, -0.0296,\n",
       "                       0.0248,  0.0164,  0.0080,  0.0439, -0.0256, -0.0213,  0.0053,  0.0067,\n",
       "                       0.0025, -0.0117, -0.0139, -0.0202,  0.0104, -0.0056,  0.0295,  0.0389,\n",
       "                       0.0347, -0.0263,  0.0114, -0.0407,  0.0029,  0.0330, -0.0109,  0.0093,\n",
       "                       0.0185, -0.0436, -0.0021,  0.0105,  0.0289,  0.0050,  0.0291, -0.0307,\n",
       "                      -0.0111,  0.0218,  0.0322, -0.0216, -0.0034,  0.0108,  0.0139,  0.0242,\n",
       "                      -0.0039, -0.0260,  0.0204, -0.0051, -0.0184, -0.0102, -0.0113, -0.0258,\n",
       "                      -0.0226,  0.0083,  0.0291,  0.0410, -0.0232, -0.0176, -0.0105, -0.0313,\n",
       "                       0.0339,  0.0156, -0.0041,  0.0539, -0.0181, -0.0149,  0.0247,  0.0223,\n",
       "                       0.0065, -0.0142,  0.0087,  0.0416, -0.0010, -0.0007, -0.0284,  0.0091,\n",
       "                      -0.0299, -0.0273, -0.0013,  0.0311,  0.0177,  0.0006, -0.0274,  0.0434,\n",
       "                       0.0060,  0.0048, -0.0065,  0.0375,  0.0143, -0.0056,  0.0025,  0.0400],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.2.weight',\n",
       "              tensor([[ 0.1031, -0.0784,  0.1225,  ...,  0.0166, -0.0647,  0.0448],\n",
       "                      [-0.0746, -0.2045,  0.0213,  ...,  0.0200,  0.0301,  0.0594],\n",
       "                      [-0.0485,  0.1501, -0.0747,  ..., -0.0354, -0.0677,  0.0100],\n",
       "                      ...,\n",
       "                      [ 0.3010, -0.0592, -0.0250,  ..., -0.1353, -0.0817, -0.0257],\n",
       "                      [ 0.0583, -0.0296, -0.0965,  ...,  0.1907,  0.0751, -0.0286],\n",
       "                      [-0.0687,  0.1230,  0.0270,  ...,  0.0339,  0.0858, -0.0454]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.2.bias',\n",
       "              tensor([ 3.5799e-03,  3.5292e-03, -1.9715e-02, -1.0328e-02,  1.7350e-02,\n",
       "                      -1.7284e-02,  9.3694e-04, -1.8285e-02, -6.7587e-03,  3.6638e-03,\n",
       "                      -1.4437e-02,  1.9942e-02, -2.1250e-02, -2.2902e-02,  2.3250e-02,\n",
       "                      -9.0199e-03, -2.0914e-02,  1.6462e-02,  1.6864e-02,  1.6971e-02,\n",
       "                       1.0805e-02,  9.4597e-03,  6.0784e-04, -3.4437e-03, -1.5691e-02,\n",
       "                       1.0027e-03,  1.3647e-02, -5.8386e-03, -1.6246e-02,  1.9832e-02,\n",
       "                       1.8696e-02, -1.8948e-02, -6.1973e-03,  1.1848e-02,  1.3520e-02,\n",
       "                      -5.1360e-03, -1.0215e-02,  1.6143e-02,  1.0493e-02,  9.4610e-03,\n",
       "                      -2.1828e-02,  1.2389e-02, -2.3929e-02, -1.5668e-02, -5.4613e-04,\n",
       "                       9.8429e-03, -4.7456e-03,  1.1693e-02,  1.6548e-02, -2.3037e-02,\n",
       "                       6.6384e-04, -2.4440e-03,  1.8023e-02, -1.5377e-02,  2.9876e-03,\n",
       "                       1.4220e-02, -6.3246e-03,  6.4127e-03,  2.1948e-02,  1.6072e-02,\n",
       "                      -3.6497e-03,  7.4768e-03,  1.9767e-02, -1.7684e-02, -5.7277e-03,\n",
       "                      -5.6413e-03, -1.7375e-02,  1.5375e-02,  1.7958e-02, -1.6137e-02,\n",
       "                      -1.2186e-02,  1.5668e-05,  2.5710e-03, -6.8798e-03, -1.8157e-02,\n",
       "                      -1.4367e-02, -6.2862e-03, -1.1924e-02, -1.5660e-02,  1.9036e-02,\n",
       "                      -2.3311e-02,  9.5750e-03, -1.9810e-02,  2.0722e-02,  6.2475e-04,\n",
       "                      -1.5477e-02,  1.1501e-02, -1.0731e-02,  2.7525e-03, -8.3308e-03,\n",
       "                      -2.5942e-02, -1.4650e-03, -8.8326e-03,  2.0180e-03, -7.1282e-03,\n",
       "                       4.4672e-03,  4.1499e-03,  1.4123e-02, -3.6176e-03,  1.8223e-02,\n",
       "                       2.1647e-03,  6.9139e-03,  1.0047e-03, -4.0867e-03,  1.2341e-02,\n",
       "                      -7.2736e-03,  2.3376e-02,  1.7278e-02,  6.8736e-04, -1.8320e-02,\n",
       "                       1.3428e-02, -1.5306e-02,  2.0008e-02,  1.6215e-06,  1.6775e-02,\n",
       "                      -1.5133e-02, -1.3126e-02, -1.2041e-02,  1.5071e-02, -1.9596e-02,\n",
       "                      -2.3280e-02,  1.5094e-02, -2.1058e-02,  2.0434e-02, -1.8828e-03,\n",
       "                      -5.4423e-03, -2.1646e-02,  5.7857e-03,  2.1414e-02,  1.6875e-03,\n",
       "                       2.2360e-02, -2.1373e-02, -9.8489e-03,  1.6259e-02,  1.7101e-02,\n",
       "                      -2.2432e-02,  1.9357e-02, -1.9886e-02, -2.0919e-02, -1.9031e-02,\n",
       "                      -1.6509e-03, -1.6547e-03,  1.5982e-02,  5.1847e-03,  1.9170e-02,\n",
       "                       1.7896e-02,  2.4410e-03,  1.1951e-02, -2.4551e-02,  1.6849e-02,\n",
       "                      -1.9074e-02, -2.2394e-02, -2.1093e-02,  2.0049e-02, -1.7392e-02,\n",
       "                       2.3051e-02, -1.7531e-02,  4.6713e-04, -3.2929e-03,  3.0393e-03,\n",
       "                       1.0845e-02, -2.2677e-02, -1.7766e-02, -5.2143e-03, -1.9969e-02,\n",
       "                      -2.1128e-02, -1.7207e-02,  3.5592e-03,  3.8090e-03,  1.3139e-02,\n",
       "                      -2.2284e-02,  1.3133e-02, -1.9177e-03, -1.9009e-02, -2.1424e-02,\n",
       "                       1.5563e-03,  1.4668e-02, -2.0922e-02, -2.2657e-03,  2.2310e-02,\n",
       "                      -1.1378e-02, -2.0817e-02,  6.2105e-04,  1.2367e-02, -4.5331e-03,\n",
       "                       1.0558e-02,  5.1795e-03, -2.2744e-02,  1.8500e-02, -2.2728e-02,\n",
       "                      -1.8266e-02,  4.4167e-03,  2.2934e-02, -1.0485e-02, -1.5243e-02,\n",
       "                      -3.7956e-03, -1.3557e-02, -1.7258e-02,  2.4479e-02, -2.1338e-02,\n",
       "                      -1.9147e-02,  2.0108e-02,  6.1759e-03,  8.7468e-03, -3.2058e-03,\n",
       "                       1.2333e-02, -2.0609e-02, -3.1282e-03, -2.4115e-03, -1.0368e-02,\n",
       "                      -1.8686e-02, -9.9143e-03, -1.2893e-02, -7.8900e-03, -1.9347e-02,\n",
       "                       2.9915e-03,  1.7967e-02, -1.4676e-02,  2.0105e-02, -5.5169e-03,\n",
       "                       1.9404e-02,  2.3219e-02,  1.8098e-02, -5.3687e-03, -5.9559e-03,\n",
       "                      -4.4813e-03, -1.5034e-03, -1.3383e-02,  1.9927e-02, -3.6679e-03,\n",
       "                       1.7204e-02, -5.4026e-03,  1.2775e-02,  2.2480e-03, -4.0149e-03,\n",
       "                      -4.6519e-03,  2.7157e-02,  2.2412e-03, -2.5997e-03, -2.6912e-02,\n",
       "                       2.0699e-02, -1.8649e-02,  5.4057e-04,  2.2096e-02, -6.5883e-04,\n",
       "                      -8.6348e-05,  2.0106e-02,  1.8275e-02, -1.8689e-02,  3.5094e-03,\n",
       "                       1.7725e-02,  7.9392e-03, -1.5728e-03,  1.8433e-02,  5.5552e-03,\n",
       "                      -6.0163e-03], device='cuda:0')),\n",
       "             ('action_net.weight',\n",
       "              tensor([[ 0.0012,  0.0227, -0.0473,  ..., -0.0274, -0.0431,  0.0210],\n",
       "                      [ 0.0113,  0.0733, -0.0241,  ..., -0.0195,  0.0170, -0.0060],\n",
       "                      [ 0.0015, -0.0290,  0.0109,  ..., -0.0131,  0.0136,  0.0368],\n",
       "                      ...,\n",
       "                      [-0.0149,  0.0221,  0.0098,  ...,  0.0015, -0.0339,  0.0399],\n",
       "                      [ 0.0411, -0.0210,  0.0034,  ...,  0.0035, -0.0071,  0.0404],\n",
       "                      [ 0.0169, -0.0078,  0.0210,  ..., -0.0110, -0.0452, -0.0073]],\n",
       "                     device='cuda:0')),\n",
       "             ('action_net.bias',\n",
       "              tensor([ 7.1976e-03, -5.1840e-05, -1.8893e-02, -1.4768e-02, -2.1590e-02,\n",
       "                      -5.3293e-04, -2.1903e-02, -3.6274e-02, -6.4636e-03,  2.2269e-02,\n",
       "                      -1.0875e-02,  3.7804e-02, -1.9634e-02, -3.0975e-03,  7.7602e-03,\n",
       "                       2.1053e-02, -1.2791e-02,  4.7547e-02, -5.0211e-04,  3.2260e-02,\n",
       "                       2.1611e-02,  4.7714e-02,  4.0008e-02, -3.6381e-03, -1.5408e-02,\n",
       "                       2.9937e-02,  1.1037e-02, -1.4739e-02, -3.4997e-02,  3.0742e-02,\n",
       "                       1.1662e-02,  4.3333e-03, -4.1599e-04, -2.0226e-02,  3.1167e-02,\n",
       "                       4.4749e-03, -1.5468e-02,  1.3803e-02,  3.2176e-02,  1.3382e-02,\n",
       "                      -1.9587e-02,  4.2042e-03,  2.7800e-03,  3.3353e-02,  2.5322e-02,\n",
       "                       3.6295e-02, -2.6026e-03, -1.0599e-02, -2.5099e-02,  1.8091e-02,\n",
       "                       6.1407e-02,  1.6070e-02,  5.6761e-02,  4.9916e-03,  2.9991e-02,\n",
       "                      -1.8809e-02, -1.3155e-03,  1.8749e-03, -1.5828e-02, -5.5678e-03,\n",
       "                      -2.2151e-02, -1.0909e-02, -5.0003e-02, -1.3498e-02], device='cuda:0')),\n",
       "             ('value_net.weight',\n",
       "              tensor([[-3.3037e-03,  5.3284e-03, -9.3936e-02,  9.3759e-02, -7.8912e-02,\n",
       "                        1.7651e-02, -3.1864e-03,  1.4838e-02,  3.6118e-02, -2.1965e-03,\n",
       "                       -1.8197e-02, -1.1277e-01,  3.9909e-02,  1.2386e-01,  7.8707e-02,\n",
       "                        4.8020e-02, -5.5264e-02,  2.9150e-02,  1.2501e-01,  7.0784e-02,\n",
       "                        1.1205e-01,  5.6027e-03, -5.6052e-03, -1.5464e-03, -2.6084e-02,\n",
       "                        1.8369e-02,  6.4251e-02,  5.6639e-03, -8.8315e-03, -4.6602e-02,\n",
       "                       -5.5952e-02,  1.3690e-01,  2.1227e-02,  5.3258e-02, -9.6172e-03,\n",
       "                        4.0385e-04, -1.2305e-03, -1.4693e-01,  1.1193e-01, -1.1170e-03,\n",
       "                        3.9019e-02, -2.3649e-02,  9.3961e-02, -9.2013e-02,  4.6556e-03,\n",
       "                        2.4766e-02, -1.1856e-02, -4.0379e-02, -9.1541e-03, -4.7995e-02,\n",
       "                        1.2343e-03, -1.1859e-03, -9.0648e-02, -1.1912e-01, -3.0946e-03,\n",
       "                       -4.7574e-02,  1.3759e-02, -3.0798e-03, -8.3888e-02,  3.3826e-02,\n",
       "                        2.1512e-03,  3.5112e-03, -3.0947e-02, -3.9469e-02,  1.4467e-03,\n",
       "                        5.8429e-03, -4.3625e-02, -9.0233e-03,  6.3658e-02,  1.1783e-01,\n",
       "                       -8.9585e-02, -3.9797e-03,  2.1342e-03,  1.6873e-03, -4.2570e-02,\n",
       "                        1.7917e-02, -4.5486e-04, -6.3664e-02,  3.0962e-02,  7.5418e-02,\n",
       "                       -8.5835e-02, -3.8027e-03, -5.4829e-02, -8.5183e-02,  4.9747e-03,\n",
       "                       -1.7616e-02,  3.7681e-02, -8.1497e-03, -3.2110e-02, -4.7939e-03,\n",
       "                        5.9446e-02,  1.2871e-04, -1.1236e-03,  1.0122e-04,  5.9017e-03,\n",
       "                        3.4359e-03, -2.4740e-03, -9.4853e-02, -2.3892e-03, -8.1743e-02,\n",
       "                       -1.4456e-04, -1.7734e-03,  5.2059e-03, -2.7922e-03, -1.3474e-02,\n",
       "                        3.6450e-02,  7.0219e-02,  6.5782e-02, -1.7412e-03,  4.3386e-02,\n",
       "                       -3.6895e-03, -4.2182e-02, -5.8059e-02, -2.2665e-03, -5.7482e-02,\n",
       "                       -9.4000e-03,  3.1009e-02, -6.0081e-02,  2.9139e-02,  1.0468e-01,\n",
       "                        1.1024e-01,  8.5318e-02, -6.7113e-02, -1.1693e-01,  2.0401e-03,\n",
       "                        9.4724e-03,  4.8819e-02,  7.7481e-03,  7.7007e-02, -2.4200e-03,\n",
       "                        8.8408e-02, -5.8496e-02, -5.1439e-04,  9.0237e-02,  3.7648e-02,\n",
       "                        6.7163e-02, -6.7338e-02,  1.0306e-01,  5.6972e-02,  6.1626e-02,\n",
       "                        5.8335e-03,  4.4375e-03, -7.0211e-02,  2.6161e-03,  5.2987e-02,\n",
       "                       -6.7511e-02, -2.0358e-02,  1.0349e-01,  5.6568e-02,  2.9279e-02,\n",
       "                       -7.6973e-02,  5.6301e-02,  3.8001e-02, -7.7740e-02,  2.8528e-02,\n",
       "                        5.9497e-02, -5.6108e-02, -2.2918e-03,  6.8027e-04, -4.1869e-03,\n",
       "                        1.2244e-03,  5.1292e-02,  3.3933e-02,  1.4602e-03, -4.8650e-02,\n",
       "                        1.5021e-01,  2.3874e-02,  9.1171e-04,  5.1501e-04,  3.2667e-02,\n",
       "                        6.0254e-02,  4.0823e-02,  6.8889e-04, -5.0441e-02,  2.6259e-02,\n",
       "                       -2.2578e-03, -1.6464e-01, -4.4331e-02,  1.3884e-03, -8.8885e-02,\n",
       "                       -6.9349e-02,  1.5955e-01,  5.2212e-03,  3.4174e-02, -1.0216e-02,\n",
       "                       -4.7145e-02, -5.4640e-03,  4.1004e-02,  1.3680e-01,  3.7153e-02,\n",
       "                        1.3271e-01, -1.7563e-02, -7.9908e-02, -5.3408e-03,  6.6469e-02,\n",
       "                       -3.7583e-03, -7.7805e-02, -3.3602e-02, -8.1072e-02,  8.2813e-02,\n",
       "                       -5.8939e-02,  2.5783e-02,  5.9611e-03,  5.1634e-02, -1.8126e-03,\n",
       "                       -2.9491e-02,  6.7121e-02, -3.0367e-03, -3.8643e-03, -9.6008e-02,\n",
       "                       -1.0055e-01,  9.4307e-03,  2.6973e-02, -7.6093e-03, -3.8869e-02,\n",
       "                       -1.6433e-03, -5.9397e-02, -7.7529e-02,  5.9596e-02, -8.4991e-03,\n",
       "                        4.8007e-02, -5.4996e-02, -6.5658e-02,  1.5903e-04, -9.2767e-02,\n",
       "                        7.7916e-03,  1.5767e-04, -5.0047e-02, -3.0773e-02, -8.7600e-02,\n",
       "                        8.4599e-02,  1.3865e-03,  9.1907e-03, -1.3307e-04, -4.5890e-03,\n",
       "                        1.2302e-03, -6.6371e-02,  2.2931e-03, -3.8944e-03,  1.7272e-02,\n",
       "                       -2.2133e-02, -5.1664e-02,  5.3131e-04, -1.9438e-02,  3.2887e-02,\n",
       "                       -1.1220e-02, -4.9104e-02,  3.0505e-02,  2.3949e-02, -6.2865e-04,\n",
       "                        7.8438e-02, -3.3102e-04, -1.7982e-03, -3.1845e-02,  3.5578e-02,\n",
       "                        1.4502e-03]], device='cuda:0')),\n",
       "             ('value_net.bias', tensor([0.0009], device='cuda:0'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb3_model.policy.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01be5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
